{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "residential-soccer",
   "metadata": {
    "id": "residential-soccer",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Week 01 - End-to-End Machine Learning\n",
    "\n",
    "### Aims\n",
    "\n",
    "By the end of this notebook you \n",
    "\n",
    "* understand the basics of end-to-end machine learning project\n",
    "* play with some data pre-processing tools\n",
    "* understand the idea of Resamplers and Transformers\n",
    "* understand the importance of data partitioning\n",
    "* fit some basic models on your data\n",
    "\n",
    "### Topics\n",
    "\n",
    "1. [Problem Understanding and Setup](#setup)\n",
    "\n",
    "2. [Exploratory Data Analysis](#eda)\n",
    "\n",
    "3. [Data Preparation](#prep)\n",
    "\n",
    "4. [Model Exploration](#explore)\n",
    "\n",
    "5. [Summary](#sum)\n",
    "\n",
    "6. [Extra](#extra)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welcome-battery",
   "metadata": {
    "id": "welcome-battery",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## General Information\n",
    "\n",
    "**To kick start this course off we are going to walk through an end-to-end machine learning project!** \n",
    "\n",
    "Don't worry about understanding all the specifics just yet, the course has just started and we'll be delving deeper into a lot of what is covered here over the coming weeks. Instead the aim here is to get a broad overview of how an ML project looks like and to get some experience playing around with some of the techniques that we will learn more of as the course goes on. \n",
    "\n",
    "- You will find that in a lot of cases you won't need to write much code to answer the exercises (we're just getting started after all!), but as the weeks go on you will find some exercises will require more code to answer. \n",
    "\n",
    "- Also as a lot of stuff will be new this week, there is a lot of written text here to help guide you along... don't worry, not all these notebooks are this wordy!\n",
    "\n",
    "To engage with the workshop material, it is assumed that you have a decent knowledge of data manipulation and visualisation in Python from previous experience and courses. As Python Programming (MATH11199) is a pre-requisite for this course, you may want to recap on some aspects from that course. Some of this material is included on the MLP learn page in the \"Week 0\" folder. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sufficient-allocation",
   "metadata": {
    "id": "sufficient-allocation",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This workshop will broadly use the [\"Machine Learning Project Checklist\"](https://github.com/ageron/handson-ml/blob/master/ml-project-checklist.md) from Geron (2019) as a stucture:\n",
    "> - Frame the problem and look at the big picture.\n",
    "> - Get the data.\n",
    "> - Explore the data and gain insights.\n",
    "> - Prepare the data to better expose the underlying data patterns to Machine Learning algorithms.\n",
    "> - Explore many different models and shortlist the best ones.\n",
    "> - Fine-tune your models and combine them into a great solution.\n",
    "> - Present your solution.\n",
    "> - Launch, monitor, and mantain your system.\n",
    "\n",
    "We will cover a number of them today and by the end of the course you should be familiar with all of the steps above, apart from the last one (skills for this step are beyond the scope of the course)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "completed-chile",
   "metadata": {
    "id": "completed-chile"
   },
   "source": [
    "# 1. Problem Understanding and Setup <a id='setup'></a>\n",
    "\n",
    "Lets start by examining an example problem based on [previous research](https://www.sciencedirect.com/science/article/abs/pii/S0167923609001377?via%3Dihub)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faced-marathon",
   "metadata": {
    "id": "faced-marathon",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1.1. Problem\n",
    "You have been hired by a Portugese wine company that is looking to invest in new technologies for its wine making and selling processes. They are looking to make a _\"vinho verde\"_ (commonly a white or red wine) and are intested in developing models that can be used to improve their wine making (by identifying the most influential factors) and to stratify their wines (useful for setting prices). For the sake of this workshop we are going to focus on the latter problem, although you may want to come back in later weeks to try tackle finding influential factors.\n",
    "\n",
    "From this description we have our objectives. At this stage, if working with a client on the project, we may want to discuss in broad terms some additional points. Lets look back at some of the questions we could try ask (as detailed in the lecture):\n",
    "\n",
    "> - What are their current solutions (baseline model)? \n",
    "> - How should performance be measured so it aligns with research/buisness objectives?\n",
    "> - What are the minimal performance thresholds we are aiming to achieve?\n",
    "> - Is human expertise available to help the project?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinct-lobby",
   "metadata": {
    "id": "distinct-lobby"
   },
   "source": [
    "## 1.2. Workspace\n",
    "Before downloading any data we should think about our workspace. In this course we are going to be primarily be using .ipynb notebooks in the workshops. A notebook environment is very useful for data science projects as it allows for rapid testing of ideas with on-screen visualisation of the results. "
   ]
  },
  {
   "attachments": {
    "Screenshot%202023-01-12%20at%2011.57.53.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "TOFtLcQhWzLh",
   "metadata": {
    "id": "TOFtLcQhWzLh",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1.2.1. Uploading your files to the Noteable\n",
    "\n",
    "Officially, when you click the **Noteable LTI 1.3.** icon in the course Learn page, you can reach out to the related service. \n",
    "\n",
    "![Screenshot%202023-01-12%20at%2011.57.53.png](attachment:Screenshot%202023-01-12%20at%2011.57.53.png)\n",
    "\n",
    "Currently (October 2022), there are various available notebooks on a dropdown list, the one that we need is **Standard Notebook (Python 3)**. When you just click **Start** button and then **Reconnect**, you will have an access to the **Jupyter environment** via Noteable tool. \n",
    "\n",
    "Whenever you open a new Python notebook from the New button on the upper right, you will get an empty notebook to work. This notebook will be saved in your noteable account, when you click save button on the above panel after making any changes.  \n",
    "\n",
    "To keep things organised, you can also create a folder \"MLP\" within your account, and then a sub-directory for each week like \"Week-j\". In general, for the workshop materials, this process will be automatic by following a couple of button clicks. Alternatively, if you do this manually, you can then upload the main .ipynb and all necessary files from Learn page to your \"Week-j\" folder to work with. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tSMNDWtZJViB",
   "metadata": {
    "id": "tSMNDWtZJViB"
   },
   "source": [
    "__Reminder__ \n",
    "\n",
    "- You may need to restart the runtime several times in the workshop, but you will not need to re-upload or unzip files again. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minus-nickel",
   "metadata": {
    "id": "minus-nickel"
   },
   "source": [
    "### 1.2.2. Displaying solutions\n",
    "\n",
    "- Solutions will be released after the workshop hand-in deadline via noteable and the course Learn page regularly.   \n",
    "\n",
    "- Once released you will be able to run the given files in your noteable account, which will allow you to reveal the solutions.\n",
    "\n",
    "For the details about the use of noteable, please have a look at the related video shared in Learn page, \n",
    "under week-1. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SXjqgc94h4PM",
   "metadata": {
    "id": "SXjqgc94h4PM"
   },
   "source": [
    "### 1.2.3. Packages\n",
    "\n",
    "Now lets load in some packages to get us started. The followings are widely used libraries to start working with Python in general. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "hungarian-ending",
   "metadata": {
    "id": "hungarian-ending"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de70f59d",
   "metadata": {},
   "source": [
    "If you need to install any packages from scratch, you need to install related library before calling it. For instance, feature engine is a Python library for Feature Engineering and Selection that we need to know. \n",
    "\n",
    "- It is a Python library with multiple transformers to engineer and select features to use in machine learning models.\n",
    "\n",
    "- Feature-engine preserves Scikit-learn functionality with methods fit() and transform() to learn parameters from and then transform the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3589781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting feature_engine\n",
      "  Using cached feature_engine-1.5.2-py2.py3-none-any.whl (290 kB)\n",
      "Requirement already satisfied: statsmodels>=0.11.1 in /opt/conda/lib/python3.9/site-packages (from feature_engine) (0.13.2)\n",
      "Requirement already satisfied: numpy>=1.18.2 in /opt/conda/lib/python3.9/site-packages (from feature_engine) (1.21.6)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from feature_engine) (1.1.1)\n",
      "Requirement already satisfied: pandas>=1.0.3 in /opt/conda/lib/python3.9/site-packages (from feature_engine) (1.4.2)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.9/site-packages (from feature_engine) (1.7.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.9/site-packages (from pandas>=1.0.3->feature_engine) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.9/site-packages (from pandas>=1.0.3->feature_engine) (2022.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn>=1.0.0->feature_engine) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn>=1.0.0->feature_engine) (1.2.0)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /opt/conda/lib/python3.9/site-packages (from statsmodels>=0.11.1->feature_engine) (0.5.2)\n",
      "Requirement already satisfied: packaging>=21.3 in /opt/conda/lib/python3.9/site-packages (from statsmodels>=0.11.1->feature_engine) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging>=21.3->statsmodels>=0.11.1->feature_engine) (3.0.8)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from patsy>=0.5.2->statsmodels>=0.11.1->feature_engine) (1.16.0)\n",
      "Installing collected packages: feature_engine\n",
      "Successfully installed feature_engine-1.5.2\n"
     ]
    }
   ],
   "source": [
    "# One of the packages that we need later\n",
    "# !pip install feature_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549c8ffa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In some cases, one can need a component of the whole library. If this is the case, it is possible for importing specific things from a module (library), using the following lines of codes;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8658e585",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engine.imputation import DropMissingData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifteen-niagara",
   "metadata": {
    "id": "fifteen-niagara",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1.3. Data Download\n",
    "We need to get our hands on some data. In this case we are going to use The Wine Quality dataset from the UCI website (https://archive.ics.uci.edu/ml/datasets/wine+quality). As this data comes from [previous research](https://www.sciencedirect.com/science/article/abs/pii/S0167923609001377?via%3Dihub) it is already in quite a nice state. In other cases there may be a number of other preparatory stages you may need to go through.\n",
    "\n",
    "To download the data is straight-forward, we could just get it from the UCI website directly:\n",
    "\n",
    "```\n",
    "df_red = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\", delimiter=\";\")\n",
    "\n",
    "```\n",
    "\n",
    "...or we can just read it from the \"Data\" folder we've included.\n",
    "\n",
    "__Notes__\n",
    "\n",
    "- I decided to use this dataset for our first workshop as its very popular. You can find 100's of notebooks online that work with this data so its a good one to get started and improve your skills with.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cordless-grenada",
   "metadata": {
    "id": "cordless-grenada"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_red = pd.read_csv(\"Data/winequality-red.csv\", delimiter=\";\")\n",
    "df_red.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfactory-plymouth",
   "metadata": {
    "id": "satisfactory-plymouth"
   },
   "source": [
    "Before doing anything else we have to do something very important - split our data into training and test sets. \n",
    "\n",
    "> - It is important to do it early on (before looking into the data too much) as we may end up focus on specific patterns in our data which lead us to build/focus on models that do not work well on new data. \n",
    "> - If we do this, we will not have a good idea of how our model will perform in practice (generalisability)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "worldwide-baseline",
   "metadata": {
    "id": "worldwide-baseline",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>8.7</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.31</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.086</td>\n",
       "      <td>23.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1.00020</td>\n",
       "      <td>3.48</td>\n",
       "      <td>0.74</td>\n",
       "      <td>11.6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>6.1</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.066</td>\n",
       "      <td>40.5</td>\n",
       "      <td>165.0</td>\n",
       "      <td>0.99120</td>\n",
       "      <td>3.25</td>\n",
       "      <td>0.59</td>\n",
       "      <td>11.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>10.9</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.118</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.99820</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.75</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>8.8</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.088</td>\n",
       "      <td>16.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.99694</td>\n",
       "      <td>3.32</td>\n",
       "      <td>0.47</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>8.4</td>\n",
       "      <td>1.035</td>\n",
       "      <td>0.15</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.073</td>\n",
       "      <td>11.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99900</td>\n",
       "      <td>3.37</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "493            8.7             0.690         0.31             3.0      0.086   \n",
       "354            6.1             0.210         0.40             1.4      0.066   \n",
       "342           10.9             0.390         0.47             1.8      0.118   \n",
       "834            8.8             0.685         0.26             1.6      0.088   \n",
       "705            8.4             1.035         0.15             6.0      0.073   \n",
       "\n",
       "     free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "493                 23.0                  81.0  1.00020  3.48       0.74   \n",
       "354                 40.5                 165.0  0.99120  3.25       0.59   \n",
       "342                  6.0                  14.0  0.99820  3.30       0.75   \n",
       "834                 16.0                  23.0  0.99694  3.32       0.47   \n",
       "705                 11.0                  54.0  0.99900  3.37       0.49   \n",
       "\n",
       "     alcohol  quality  \n",
       "493     11.6        6  \n",
       "354     11.9        6  \n",
       "342      9.8        6  \n",
       "834      9.4        5  \n",
       "705      9.9        5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>7.7</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.114</td>\n",
       "      <td>14.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.9971</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.66</td>\n",
       "      <td>9.6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.082</td>\n",
       "      <td>21.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.9960</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.48</td>\n",
       "      <td>9.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>10.7</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.22</td>\n",
       "      <td>2.70</td>\n",
       "      <td>0.107</td>\n",
       "      <td>17.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1.0004</td>\n",
       "      <td>3.28</td>\n",
       "      <td>0.98</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>8.5</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.31</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.078</td>\n",
       "      <td>32.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.33</td>\n",
       "      <td>0.54</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1326</th>\n",
       "      <td>6.7</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.077</td>\n",
       "      <td>18.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9948</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.60</td>\n",
       "      <td>10.6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "803             7.7              0.56         0.08            2.50      0.114   \n",
       "124             7.8              0.50         0.17            1.60      0.082   \n",
       "350            10.7              0.67         0.22            2.70      0.107   \n",
       "682             8.5              0.46         0.31            2.25      0.078   \n",
       "1326            6.7              0.46         0.24            1.70      0.077   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "803                  14.0                  46.0   0.9971  3.24       0.66   \n",
       "124                  21.0                 102.0   0.9960  3.39       0.48   \n",
       "350                  17.0                  34.0   1.0004  3.28       0.98   \n",
       "682                  32.0                  58.0   0.9980  3.33       0.54   \n",
       "1326                 18.0                  34.0   0.9948  3.39       0.60   \n",
       "\n",
       "      alcohol  quality  \n",
       "803       9.6        6  \n",
       "124       9.5        5  \n",
       "350       9.9        6  \n",
       "682       9.8        5  \n",
       "1326     10.6        6  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Necessary module from sklearn library\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(df_red,           # data to split\n",
    "                                     test_size=0.2,    # we will leave 20% to test our models on later\n",
    "                                     random_state=42,  # make our work reproducable \n",
    "                                     shuffle=True)     # prevent data ordering affecting our model\n",
    "\n",
    "#Displaying the training data set\n",
    "display(train_df.head())\n",
    "\n",
    "#Displaying the testing data set\n",
    "display(test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tight-leeds",
   "metadata": {
    "id": "tight-leeds"
   },
   "source": [
    "As you can see above by the index and the code, this has shuffled our data first (`shuffle=True`) and then split our data into two sets. For the sake of later functions, we'll just reset the index so it runs from 0 to the length of the set. Even if this is not an obligatory step in general, notice that this action is to prevent problems caused by the wrong use of `.loc` or `.iloc` at a later stage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "russian-compilation",
   "metadata": {
    "id": "russian-compilation"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.7</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.31</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.086</td>\n",
       "      <td>23.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1.00020</td>\n",
       "      <td>3.48</td>\n",
       "      <td>0.74</td>\n",
       "      <td>11.6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.1</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.066</td>\n",
       "      <td>40.5</td>\n",
       "      <td>165.0</td>\n",
       "      <td>0.99120</td>\n",
       "      <td>3.25</td>\n",
       "      <td>0.59</td>\n",
       "      <td>11.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.9</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.118</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.99820</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.75</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.8</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.088</td>\n",
       "      <td>16.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.99694</td>\n",
       "      <td>3.32</td>\n",
       "      <td>0.47</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.4</td>\n",
       "      <td>1.035</td>\n",
       "      <td>0.15</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.073</td>\n",
       "      <td>11.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99900</td>\n",
       "      <td>3.37</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            8.7             0.690         0.31             3.0      0.086   \n",
       "1            6.1             0.210         0.40             1.4      0.066   \n",
       "2           10.9             0.390         0.47             1.8      0.118   \n",
       "3            8.8             0.685         0.26             1.6      0.088   \n",
       "4            8.4             1.035         0.15             6.0      0.073   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 23.0                  81.0  1.00020  3.48       0.74   \n",
       "1                 40.5                 165.0  0.99120  3.25       0.59   \n",
       "2                  6.0                  14.0  0.99820  3.30       0.75   \n",
       "3                 16.0                  23.0  0.99694  3.32       0.47   \n",
       "4                 11.0                  54.0  0.99900  3.37       0.49   \n",
       "\n",
       "   alcohol  quality  \n",
       "0     11.6        6  \n",
       "1     11.9        6  \n",
       "2      9.8        6  \n",
       "3      9.4        5  \n",
       "4      9.9        5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df = train_df.reset_index(drop = True)\n",
    "test_df = test_df.reset_index(drop = True)\n",
    "\n",
    "display(train_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polished-dispatch",
   "metadata": {
    "id": "polished-dispatch",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 2. Exploratory Data Analysis <a id='eda'></a>\n",
    "\n",
    "In this section we are going to start with exploring the wine data using methods that you will likely already be familiar with.\n",
    "\n",
    "Hopefully by now you should have a pretty good idea what we consider as data. Data can come in a broad range of forms encompassing a collection of discrete objects, numbers, words, events, facts, measurements, observations, or even descriptions of things. Processing data using exploratory data analysis (EDA) can elicit useful information and knowledge by examining the available dataset to discover patterns, spot anomalies, test hypotheses, and check assumptions using statistical measures. \n",
    "\n",
    "Lets start by looking at what varibles we have in our data to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "decreased-address",
   "metadata": {
    "id": "decreased-address"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
       "       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
       "       'pH', 'sulphates', 'alcohol', 'quality'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precise-contractor",
   "metadata": {
    "id": "precise-contractor",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Below is a __Data Dictionary__ which describes what each feature represents. Have a read through but for the sake of this workshop you don't need to worry about understanding the precise details.\n",
    "\n",
    "> - `fixed acidity`: It indicates the amount of tartaric acid in wine and is measured in g/dm$^3$.\n",
    "> - `volatile acidity`: It indicates the amount of acetic acid in the wine. It is measured in g/dm3.\n",
    "> - `citric acid`: It indicates the amount of citric acid in the wine. It is also measured in g/dm3.\n",
    "> - `residual sugar`: It indicates the amount of sugar left in the wine after the fermentation process is done. It is also measured in g/dm3.\n",
    "> - `free sulfur dioxide`: It measures the amount of sulfur dioxide (SO2) in free form. It is also measured in g/dm3. \n",
    "> - `total sulfur dioxide`: It measures the total amount of SO2 in the wine. This chemical works as an antioxidant and antimicrobial agent.\n",
    "> - `density`: It indicates the density of the wine and is measured in g/dm3.\n",
    "> - `pH`: It indicates the pH value of the wine. The range of value is between 0 to 14.0, which indicates very high acidity, and 14 indicates basic acidity. \n",
    "> - `sulphates`: It indicates the amount of potassium sulphate in the wine. It is also measured in g/dm3.\n",
    "> - `alcohol`: It indicates the alcohol content in the wine. \n",
    "> - `quality`: It indicates the quality of the wine, which is ranged from 1 to 10. Here, the higher the value is, the better the wine.\n",
    "\n",
    "As further reading, you can check out the given source below: \n",
    "- Mukhiya, S. K., & Ahmed, U. (2020). Hands-On Exploratory Data Analysis with Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "associate-seeker",
   "metadata": {
    "id": "associate-seeker"
   },
   "source": [
    "Now onto the tasks, where we will begin to get a basic understanding of the data. \n",
    "\n",
    ">- You will see some CORE and EXTRA tasks for the first workshop. \n",
    ">- Primarily, you should aim to complete the CORE components during the WS session, but afterwards try to complete the EXTRA tasks for your self-learning process. \n",
    ">- In general, weekly hand-ins attached to our WS sessions, would be beneficial for your projects in the long run\n",
    ">- In some Exercises, you will see some beneficial hints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rural-ownership",
   "metadata": {
    "id": "rural-ownership"
   },
   "source": [
    "---\n",
    "\n",
    "###  Exercise 1 (CORE)\n",
    "\n",
    "Examine the datatypes for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protective-ivory",
   "metadata": {
    "id": "protective-ivory"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fancy-theology",
   "metadata": {
    "id": "fancy-theology"
   },
   "source": [
    "---\n",
    " \n",
    "###  Exercise 2  (CORE)\n",
    "\n",
    "Get some descriptive information about the data (e.g. mean, standard deviation, ect.). \n",
    "- Is there anything in particular you notice in any of the variables that may warrent further examination?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58775cb5",
   "metadata": {
    "id": "58775cb5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "respected-alaska",
   "metadata": {
    "id": "respected-alaska"
   },
   "source": [
    "---\n",
    "As the problem we are trying to address is to stratify the wines we will be using \"quality\" as the output/target varible for our models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "affected-registrar",
   "metadata": {
    "id": "affected-registrar"
   },
   "outputs": [],
   "source": [
    "output = \"quality\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proprietary-medicine",
   "metadata": {
    "id": "proprietary-medicine"
   },
   "source": [
    "Using the string above, we are going to split the data again, in a different way. This time we are going to create a pandas `Series` called `y_train`, which contains our output variable, and then remove this variable from our training `DataFrame` so that it only includes the other variables (`X_train`).\n",
    "\n",
    "__Note__\n",
    "- For visualisation purposes you may want to keep a version of the data (in this case `train_df`) with the target still in there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fossil-airplane",
   "metadata": {
    "id": "fossil-airplane"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1279, 11)\n",
      "(1279,)\n"
     ]
    }
   ],
   "source": [
    "y_train = train_df.loc[:,output]\n",
    "X_train = train_df.drop(output, axis=1)\n",
    "\n",
    "feature_names = list(X_train.columns)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6eeabc8",
   "metadata": {},
   "source": [
    "You can do a similar thing for your test data by following a similar way, as a small hands-on here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e12923",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "amended-fiber",
   "metadata": {
    "id": "amended-fiber"
   },
   "source": [
    "---\n",
    "\n",
    "###  Exercise 3  (CORE)\n",
    "\n",
    "Use `sns.countplot` to examine how many unique values are present in `y_train`.\n",
    "\n",
    "__Why might we want to do this?__\n",
    "\n",
    "Later in the course we will learn about the affects of \"imballanced\" data on models (where there is much more of one class than another)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bibliographic-exception",
   "metadata": {
    "id": "bibliographic-exception"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "delayed-merchant",
   "metadata": {
    "id": "delayed-merchant"
   },
   "source": [
    "---\n",
    "\n",
    "###  Exercise 4  (CORE)\n",
    "\n",
    "Find out if any of the features from our training set (`X_train`) are highly correlated.\n",
    "\n",
    "__Why might we want to do this?__\n",
    "- For __Linear models__ (e.g. linear or logistic regression), multicolinearity can yield varying and possibly numerically unstable solutions.\n",
    "- For __Random forests__ highly correlated features can mask feature interactions.\n",
    "- For __Model interpretability__ a simpler model is generally preferable and more easily interpretatble. \n",
    "- Generally...the learning algorithm will be __faster__ if we use this information to reduce the number of features.\n",
    "\n",
    "We will learn more about all these reasons given above in later weeks, but for now just take my word for it that its generally a good idea to remove them or (sometimes preferably) to combine them with feature extraction techniques (e.g. PCA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "atomic-bedroom",
   "metadata": {
    "id": "atomic-bedroom"
   },
   "outputs": [],
   "source": [
    "# For the size of plot, more readable figure\n",
    "sns.set(rc={'figure.figsize': (14, 8)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "permanent-sucking",
   "metadata": {
    "id": "permanent-sucking"
   },
   "source": [
    "---\n",
    "\n",
    "###  Exercise 5  (CORE)\n",
    "\n",
    "Examine the distributions (e.g. gaussian, right or left skewed?) of the different variables.\n",
    "\n",
    "__Why might we want to do this?__\n",
    "\n",
    "Some models and preparation steps assume certain distributions, as we will discuss in later weeks.\n",
    "\n",
    "<br>\n",
    "<details><summary><b><u>Hint</b></u></summary>\n",
    "You could use a histogram:\n",
    "    \n",
    "- Using Pandas: `X_train[variable_name].hist()`\n",
    "- Using Seaborn: `sns.histplot(X_train[variable_name])`\n",
    "- Using Matplotlib: `plt.hist(X_train[variable_name])`\n",
    "    \n",
    "You could also examine a probability plot (`scipy.stats.probplot(df[variable], dist=\"norm\")`) or even compute the sample skewness (`scipy.stats.skew(X_train[variable_name])`).\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "present-major",
   "metadata": {
    "id": "present-major"
   },
   "outputs": [],
   "source": [
    "# Necessary module for the probability plot \n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "violent-aberdeen",
   "metadata": {
    "id": "violent-aberdeen"
   },
   "source": [
    "# 3. Data Pre-Processing <a id='prep'></a>\n",
    "\n",
    "Now we have some familiarity with the data though our data exploration, lets start preparing our data to be modelled.\n",
    "\n",
    "From here on in, we should really be creating functions for our data transformations. This is because when we want to run data through our \"model pipeline\" in the future, rather than having to copy and paste a load of code, we can just use a series of functions. In this notebook, we will do this with our validation set and at the very end with our test set, but this would also be required if you deploy your model in a \"live\" environment. Furthermore, when refining a model it makes it easier for us to treat our preparation choices as \"hyperparameters\", meaning we can easily add or remove parts of our pipeline to see what works and what doesn't.\n",
    "\n",
    "Its also worth examining what is meant by a **\"Pipeline\"**. \n",
    "\n",
    "- A general definition is that it is just a sequence of data preparation operations that is ensured to be reproducible. \n",
    "\n",
    "- However, we may want to ensure that any functions/classes we make for our pipeline have specific attributes that work best with the tools available in our chosen machine learning library. \n",
    "\n",
    "- In this course we are mostly going to be using `Scikit-learn`, with a little `Keras` at the end for neural networks.\n",
    "\n",
    "__Scikit-learn__\n",
    "\n",
    "Scikit-learn is an open source machine learning library that supports supervised and unsupervised learning (https://scikit-learn.org/stable/getting_started.html). \n",
    "\n",
    "It also provides various tools for model fitting, data preprocessing, model selection and evaluation, and many other utilities. \n",
    "\n",
    "In Scikit-Learn a `Pipeline` is a class we can use to combine our pre-processing and modelling steps together (https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html).\n",
    "\n",
    "A `Pipeline` is useful for many reasons, including that they help prevent you from data leakage, i.e. disclosing some testing data in your training data. Objects that go into a scikit-learn `Pipeline` can either be _transformer_ or _estimator_ classes, or, if we use an imbalanced-learn `Pipeline` instead, also _resamplers_.\n",
    "\n",
    "All three of these objects (_resamplers_, _transformers_, and _estimator_) all typically have a `.fit()` method, which is used to...\n",
    "- ...validate and interpret any parameters, \n",
    "- ...validate the input data, \n",
    "- ...estimate and store attributes from the parameters and provided data, \n",
    "- ...return the fitted estimator to facilitate method chaining in a pipeline. \n",
    "\n",
    "Along with other sample properties (e.g. `sample_weight`), the `.fit()` method usually takes 2 inputs:\n",
    "\n",
    "> - The samples matrix (or design matrix) X. The size of X is typically (n_samples, n_features), which means that samples are represented as rows and features are represented as columns.\n",
    ">\n",
    "> - The target values y which are real numbers for regression tasks, or integers for classification (or any other discrete set of values). For unsupervized learning tasks, y does not need to be specified. y is usually 1d array where the i th entry corresponds to the target of the i th sample (row) of X.\n",
    ">\n",
    "> https://scikit-learn.org/stable/getting_started.html\n",
    "\n",
    "Other methods available for these objects other than `.fit()` will depend on what they are, so we will look at each of these objects in turn and then combine them into a model pipeline later in this workshop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painted-money",
   "metadata": {
    "id": "painted-money"
   },
   "source": [
    "---\n",
    "\n",
    "## 3.1. Data Cleaning\n",
    "\n",
    "At this stage in our workflow we may want to deal with duplicated/missing values and (optionally) fix/remove outliers. We'll have more of a look at outliers over the next few weeks, but for this week lets just look at the former issue.\n",
    "\n",
    "We want to remove duplicates as they may bias our fitted model. In other words, we may potentially *overfit* to this subset of points. However, care should usually be taken to check they are not _real_ data with identical values.\n",
    "\n",
    "There a number of ways we could identify duplicates, the simplest one (and the approach we'll focus on) is just to find observations with the same feature values. Of course this will not identify things such as spelling errors, missing values, address changes, use of aliases, ect. For those such things, more complicated methods along with manual assessment is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "starting-victory",
   "metadata": {
    "id": "starting-victory"
   },
   "source": [
    "###  Exercise 6  (CORE)\n",
    "\n",
    "How many duplicated observations are present in the features?\n",
    "\n",
    "<br>\n",
    "<details><summary><b><u>Hint</b></u></summary>\n",
    "\n",
    "With Pandas dataframes you can use `.duplicated()` to get a boolean of whether something is a duplicate and then use `.sum()` to count how many there are.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "known-password",
   "metadata": {
    "id": "known-password"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "popular-pride",
   "metadata": {
    "id": "popular-pride"
   },
   "source": [
    "###  Exercise 7  (CORE)\n",
    "\n",
    "Write a function named `drop_duplicated` that takes the `X_train` and `y_train` objects, and outputs these objects with the duplicate observations removed.\n",
    "\n",
    "__Notes__\n",
    "- It may be tempting to overwrite `X_train` and `y_train` while working on our pre-processing steps. __Don't do this!__ We will run these objects through these steps inside our pipeline later so if you want to test your function make sure to assign the output to tempory objects (e.g. `X_train_, y_train_`).\n",
    "- For this week (for ease), your functions can output a `pd.DataFrame` or a `np.Array`. Next week we'll look at working only with numpy arrays (which is more common)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaff4d56",
   "metadata": {},
   "source": [
    "<details><summary><b><u>Hint</b></u></summary>\n",
    "Your function could work using the following steps:\n",
    "    \n",
    "- has `X` and `y` as inputs (features and targets), \n",
    "    \n",
    "- adds the targets as a new column on the end of the features data,\n",
    "    \n",
    "- drops the duplicate observations,\n",
    "    \n",
    "- outputs the `X` and `y` separately again.\n",
    "    \n",
    "If your really stuck you can peek ahead at a later part of the workbook and find `drop_duplicated` function below\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7115dbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the comments to run this code cell\n",
    "\n",
    "def drop_duplicated(X,y):\n",
    "    df = pd.concat([X,y], axis=1)\n",
    "    df = df.drop_duplicates()\n",
    "    return df.iloc[:,:-1], df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powerful-apparel",
   "metadata": {
    "id": "powerful-apparel"
   },
   "source": [
    "---\n",
    "\n",
    "If we want to remove duplicate _observations_ from our training data using a function that is compatible with a `Pipeline`, we are going to need to turn it into a _resampler_.\n",
    "\n",
    "__Resamplers__\n",
    "\n",
    "Resamplers are classes that follow the scikit-learn API and have a sampling functionality through the `.resample()` method. Like all other scikit-learn methods, they have a `.fit()` method which is only applied during pipeline training. This means if we want to create our own resampler from scratch that is compatible with scikit-learn, we just have to make a class that has three methods; `.fit()`,  `.resample()`, and `.fit_resample()`; with the latter just chaining the other two together.\n",
    "\n",
    "Therefore to resample a dataset, each sampler implements:\n",
    "\n",
    "```\n",
    "obj.fit(data, targets)\n",
    "data_resampled, targets_resampled = obj.resample(data, targets)\n",
    "```\n",
    "\n",
    "or simply...\n",
    "\n",
    "```\n",
    "data_resampled, targets_resampled = obj.fit_resample(data, targets)\n",
    "```\n",
    "\n",
    "We'll look more into making custom pipeline functions next week, but for this week we can just wrap our function we just made in the handy `FunctionSampler` from `imblearn` to make it compatible.\n",
    "\n",
    "__Notes__\n",
    "- Imbalanced-learn (imported as imblearn) is an open source, MIT-licensed library relying on scikit-learn (imported as sklearn) and provides tools when dealing with classification with imbalanced classes.\n",
    "- We need a resampler to drop any duplicate observations in our dataset as these objects are used to reduce or increase the number of samples (observations) in both our feature data (`X_train`) and our targets (`y_train`) data.\n",
    "- _\"Unlike scikit-learn, imbalanced-learn provides support for pandas in/out. Therefore providing a dataframe, will output as well a dataframe\"_<sup>1</sup>.\n",
    "- Don't worry if you are stuggling to understand classes as we introduce them this week, we'll get more practice over the coming weeks!\n",
    "\n",
    "1. https://imbalanced-learn.org/stable/introduction.html\n",
    "2. https://imbalanced-learn.org/stable/auto_examples/applications/plot_outlier_rejections.html#sphx-glr-auto-examples-applications-plot-outlier-rejections-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9dfb57fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Using cached imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Collecting imbalanced-learn\n",
      "  Using cached imbalanced_learn-0.10.1-py3-none-any.whl (226 kB)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (1.21.6)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /opt/conda/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (1.1.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (1.7.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (1.2.0)\n",
      "Installing collected packages: imbalanced-learn, imblearn\n",
      "Successfully installed imbalanced-learn-0.10.1 imblearn-0.0\n"
     ]
    }
   ],
   "source": [
    "# Install the imblearn library first by\n",
    "# !pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "meaningful-burning",
   "metadata": {
    "id": "meaningful-burning"
   },
   "outputs": [],
   "source": [
    "# Call the necessary part of the module\n",
    "from imblearn import FunctionSampler\n",
    "\n",
    "# create a sampler using our function\n",
    "duplicated_sampler = FunctionSampler(func=drop_duplicated,    # our custom function\n",
    "                                     validate=False)          # prevents both inputs being changed to numpy arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b042e0",
   "metadata": {},
   "source": [
    "Now above-created `duplicated_sampler` is ready to use for the next exercise. Note that turning-off **validation** allows to use the `FunctionSampler` with any type of data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "three-revolution",
   "metadata": {
    "id": "three-revolution"
   },
   "source": [
    "---\n",
    "\n",
    "###  Exercise 8  (CORE)\n",
    "\n",
    "Using `.fit` and `.resample`, or `.fit_resample`, check to see if the `duplicated_sampler` reduces the number of observations in the training data.\n",
    "\n",
    "__Note__\n",
    "- Make sure to not overwrite your training data!\n",
    "\n",
    "<br />\n",
    "<details><summary><b><u>Hint</b></u></summary>    \n",
    "Consider combining the defined `duplicated_sampler` and `.fit_resample`.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "characteristic-winter",
   "metadata": {
    "id": "characteristic-winter"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "sapphire-calculation",
   "metadata": {
    "id": "sapphire-calculation"
   },
   "source": [
    "---\n",
    "\n",
    "###  Exercise 9  (CORE)\n",
    "\n",
    "Are there any missing values in the training data? \n",
    "- Can you think of any options we would have to account for them?\n",
    "\n",
    "__Why might we want to do this?__\n",
    "\n",
    "Bear in mind that most models (including all models in scikit-learn) cannot handle missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italic-tunisia",
   "metadata": {
    "id": "italic-tunisia"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "disciplinary-accident",
   "metadata": {
    "id": "disciplinary-accident"
   },
   "source": [
    "---\n",
    "\n",
    "###  Exercise 10 (EXTRA)\n",
    "\n",
    "Create a `Pipeline` compatible resampler that could remove any NA values from the data.\n",
    "\n",
    "<br />\n",
    "<details><summary><b><u>Hint</b></u></summary>\n",
    "    \n",
    "It will be very similar to using the other resampler above except using `.dropna()`.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arabic-apartment",
   "metadata": {
    "id": "arabic-apartment"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "historical-minority",
   "metadata": {
    "id": "historical-minority"
   },
   "source": [
    "---\n",
    "\n",
    "## 3.2. Feature Selection\n",
    "\n",
    "This optional step can occour at many points during out ML pipeline development. Feature selection is typically used to drop attributes that provide no useful information for the task. It is part of __Dimension Reduction__ (alongside feature extraction) which we will cover in more detail in week 3.\n",
    "\n",
    "As feature selection reduces the number of _features_ (not observations!) in our data, meaning we don't need to change our _target_ data (y), in a `Pipeline` these are called _\"transformers\"_.\n",
    "\n",
    "__Transformers__\n",
    "\n",
    "- Transformers in Scikit-Learn [clean](https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing), [reduce](https://scikit-learn.org/stable/modules/unsupervised_reduction.html#data-reduction), [expand](https://scikit-learn.org/stable/modules/kernel_approximation.html#kernel-approximation), or [generate](https://scikit-learn.org/stable/modules/feature_extraction.html#feature-extraction) feature representations.\n",
    "\n",
    "- Transformers are classes with a `.fit()` method, which learn model parameters (e.g. mean and standard deviation for normalization) from a training set, and a `.transform()` method which applies this transformation model to data<sup>1</sup>. To create a custom transformer, all you need is to create a class that implements three methods: `fit()`, `transform()`, and `fit_transform()`.\n",
    "\n",
    "Therefore to transform a dataset, each sampler implements:\n",
    "\n",
    "```\n",
    "obj.fit(data)\n",
    "data_transformed = obj.transform(data)\n",
    "```\n",
    "\n",
    "or simply...\n",
    "\n",
    "```\n",
    "data_transformed = obj.fit_transform(data)\n",
    "```\n",
    "\n",
    "1. https://scikit-learn.org/stable/data_transforms.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civil-cannon",
   "metadata": {
    "id": "civil-cannon"
   },
   "source": [
    "---\n",
    "\n",
    "This week lets add a basic feature selection technique into our pipeline: dropping any feature that is highly correlated with another feature (we looked at correlated features in Exercise 4).\n",
    "\n",
    "We could create our own feature selection transformers from scratch, however there are also a bunch of relevent pre-made transformers available to us already in `scikit-learn` and `feature_engine`, so we will use these this week.\n",
    "\n",
    "However lets do something first... as we will focus on next week, a pandas dataframe can be used with scikit-learn objects but they will typically output NumPy arrays or SciPy sparse matrices (this is quite a sensible design choice as explained [here](https://arxiv.org/abs/1309.0238)). Nevertheless, some transformers (especially those outside of the core scikit-learn library) may require a certain type of object. In the case of `feature_engine` (which we will use for feature selection in a second), they want pandas DataFrames. The functions you have already worked on may already be outputing dataframes, but lets make a function here we can put in our pipelines just in case to prevent any future errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "piano-vinyl",
   "metadata": {
    "id": "piano-vinyl"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.7</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.31</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.086</td>\n",
       "      <td>23.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1.00020</td>\n",
       "      <td>3.48</td>\n",
       "      <td>0.74</td>\n",
       "      <td>11.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.1</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.066</td>\n",
       "      <td>40.5</td>\n",
       "      <td>165.0</td>\n",
       "      <td>0.99120</td>\n",
       "      <td>3.25</td>\n",
       "      <td>0.59</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.9</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.118</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.99820</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.75</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.8</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.088</td>\n",
       "      <td>16.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.99694</td>\n",
       "      <td>3.32</td>\n",
       "      <td>0.47</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.4</td>\n",
       "      <td>1.035</td>\n",
       "      <td>0.15</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.073</td>\n",
       "      <td>11.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99900</td>\n",
       "      <td>3.37</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            8.7             0.690         0.31             3.0      0.086   \n",
       "1            6.1             0.210         0.40             1.4      0.066   \n",
       "2           10.9             0.390         0.47             1.8      0.118   \n",
       "3            8.8             0.685         0.26             1.6      0.088   \n",
       "4            8.4             1.035         0.15             6.0      0.073   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 23.0                  81.0  1.00020  3.48       0.74   \n",
       "1                 40.5                 165.0  0.99120  3.25       0.59   \n",
       "2                  6.0                  14.0  0.99820  3.30       0.75   \n",
       "3                 16.0                  23.0  0.99694  3.32       0.47   \n",
       "4                 11.0                  54.0  0.99900  3.37       0.49   \n",
       "\n",
       "   alcohol  \n",
       "0     11.6  \n",
       "1     11.9  \n",
       "2      9.8  \n",
       "3      9.4  \n",
       "4      9.9  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Necessary modules \n",
    "import scipy\n",
    "import warnings\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "import numpy as np\n",
    "\n",
    "# adding a single entry into warnings filter\n",
    "# warnings.simplefilter('error', UserWarning)\n",
    "\n",
    "def DfTransformer(X, column_names = None):\n",
    "    X_ = X.copy() # so we do not alter the input data\n",
    "    \n",
    "    # turn to a pandas df if a numpy array\n",
    "    if isinstance(X_, (np.ndarray, np.generic)):\n",
    "        X_ = pd.DataFrame(X_, columns = column_names)\n",
    "    \n",
    "    # turn to a pandas df if sparse\n",
    "    elif scipy.sparse.issparse(X_):\n",
    "        X_ = pd.DataFrame.sparse.from_spmatrix(X_, columns = column_names)\n",
    "    \n",
    "    # change the column names if provided and not the same\n",
    "    elif isinstance(X_, pd.DataFrame):\n",
    "        if not column_names==None and set(list(X_.columns)) == set(column_names):\n",
    "            X_.columns = column_names\n",
    "    \n",
    "    else:\n",
    "        warnings.warn(\"\"\"{} not a supported input. Input needs to be in:\n",
    "        [np.ndarray, np.generic, scipy.sparse, pd.DataFrame]\"\"\".format(type(X_)))\n",
    "        \n",
    "    return X_\n",
    "\n",
    "DataframeTransformer = FunctionTransformer(DfTransformer,\n",
    "                                           kw_args = {\"column_names\":feature_names})\n",
    "\n",
    "X_train_ = DataframeTransformer.fit_transform(X_train)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approved-investing",
   "metadata": {
    "id": "approved-investing"
   },
   "source": [
    "---\n",
    "One important issue might be the collinearity on the considered set of features/predictors. To work out, by using the `DropCorrelatedFeatures` function from `feature_engine.selection`, you can drop any features that are correlated above a certain theshold. Thereafter, you can print out the features that were dropped.\n",
    "\n",
    "\n",
    "__Notes__\n",
    "- A selected threshold in the below example (0.6 threshold) may be a bit low, but used here for demonstration purposes.\n",
    "\n",
    "- Look at the documentation (https://feature-engine.readthedocs.io/en/1.0.x/selection/DropCorrelatedFeatures.html#), how does this function decide which of the correlated features to drop?\n",
    "\n",
    "- Instead of using `.fit_resample()`, we will now need to use `.fit_transform()`.\n",
    "\n",
    "- You may want to look at `.correlated_feature_sets_` attribute of the class to see which features were correlated.\n",
    "\n",
    "- You could use `np.setdiff1d` to compare which features were dropped from a list of the original features and a list of the new datas features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "raised-gibson",
   "metadata": {
    "id": "raised-gibson"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlated Feature Groups\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'citric acid', 'density', 'fixed acidity', 'pH'},\n",
       " {'free sulfur dioxide', 'total sulfur dioxide'}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['citric acid', 'density', 'pH', 'total sulfur dioxide']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install feature_engine\n",
    "from feature_engine.selection import DropCorrelatedFeatures\n",
    "\n",
    "fs = DropCorrelatedFeatures(variables = None, \n",
    "                            method = 'pearson', \n",
    "                            threshold = 0.6)\n",
    "\n",
    "X_train_fs = fs.fit_transform(X_train)\n",
    "\n",
    "print(\"Correlated Feature Groups\")\n",
    "display(fs.correlated_feature_sets_)\n",
    "\n",
    "print(\"Dropped\")\n",
    "list(np.setdiff1d(list(X_train.columns), list(X_train_fs.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greenhouse-producer",
   "metadata": {
    "id": "greenhouse-producer"
   },
   "source": [
    "## 3.3. Feature Engineering\n",
    "\n",
    "Briefly, feature engineering means formulating appropriate features given the data, the model, and the task. We will look into it more next week.\n",
    "\n",
    "- Would feature engineering require a _\"resampler\"_ or a _\"transformer\"_ class?\n",
    "\n",
    "Feature engineering requires a _\"transformer\"_ class as we only need to alter the features and not the number of observations.\n",
    "\n",
    "For this week lets look at log transforming our features so that they have a more gaussian distribution (an assumption of a number of the models we will use later). Log transformations are useful for altering the data to have a more normal distribution as they pull in the more extreme high values relative to the median, while stretching back extreme low values away from the median."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929eda52",
   "metadata": {},
   "source": [
    "###  Exercise 11  (CORE)\n",
    "\n",
    "Using either the pre-made `LogTransformer()` from `feature_engine.transformation`, or a custom function and `sklearn.preprocessing.FunctionTransformer`, transform any skewed features using a log transform. \n",
    "\n",
    "- What is the effect of this transformation?\n",
    "\n",
    "__Note__\n",
    "- `LogTransformer` is useful before because it has a `variables` method which means you can select which features to apply it too. However, as we will learn next week, we can also limit the columns a transformer is applied to in a pipeline using a wrapper function in scikit-learn as well.\n",
    "\n",
    "<br />\n",
    "<details><summary><b><u>Hints</b></u></summary>\n",
    "\n",
    "- If the `variables` argument is left as the default (`None`), `LogTransformer()` identifies and applies the logarithm to __all the numerical variables__ in the dataset. Alternatively, you can indicate which variables we want to transform.\n",
    "\n",
    "- You cannot log transform a 0 value, so sometimes it helps to just +1.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "acquired-adoption",
   "metadata": {
    "id": "acquired-adoption"
   },
   "outputs": [],
   "source": [
    "# Necessary module from feature_engine\n",
    "from feature_engine.transformation import LogTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpha-counter",
   "metadata": {
    "id": "alpha-counter"
   },
   "source": [
    "---\n",
    "\n",
    "## 3.4. Feature Scaling\n",
    "\n",
    "As we will discuss in later weeks, many machine learning algorithms are sensitive to the scale and magnitude of the features. For these algorithms, feature scaling will improve performance and training times. Here we will \"standardise\" our features by centering the variable at zero and standardizing the variance to 1. In order to do this we subtract the mean from each observation and then divide the result by the standard deviation:\n",
    "\n",
    "$$z=\\frac{x-mean(x)}{std(x)}.$$\n",
    "\n",
    "The result of the preceding transformation is called the *z-score* and represents how many standard deviations a given observation deviates from the mean <sup>1</sup>.\n",
    "\n",
    "1. Galli, S. (2020). Python Feature Engineering Cookbook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wicked-virus",
   "metadata": {
    "id": "wicked-virus"
   },
   "source": [
    "---\n",
    "\n",
    "###  Exercise 12  (CORE)\n",
    "\n",
    "Using the `StandardScaler` transformer from `sklearn.preprocessing`, scale the features (`X_train`).\n",
    "\n",
    "<br />\n",
    "<details><summary><b><u>Hints</b></u></summary>\n",
    "\n",
    "You can use...\n",
    "- ...`.mean_` on the scaler object find the mean of the features.\n",
    "- ...`.scale_` find the standard deviation value of the features.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dated-boring",
   "metadata": {
    "id": "dated-boring"
   },
   "outputs": [],
   "source": [
    "# Necessary module from sklearn\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recorded-hygiene",
   "metadata": {
    "id": "recorded-hygiene"
   },
   "source": [
    "---\n",
    "\n",
    "###  Exercise 13 (EXTRA)\n",
    "\n",
    "Using the handy conversation function `sklearn.preprocessing.FunctionTransformer`, make transformer that standardises our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "micro-majority",
   "metadata": {
    "id": "micro-majority"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "southeast-production",
   "metadata": {
    "id": "southeast-production"
   },
   "source": [
    "---\n",
    "\n",
    "# 4. Model Exploration <a id='explore'></a>\n",
    "\n",
    "Now you would explore a series of models from different machine learning categories (e.g. linear, non-linear, forests, neural networks). For this workshop we are only going to check a few models on their default parameters until we learn more about them thoughout the course.\n",
    "\n",
    "Before moving on we are going to split our data again into a training and validation set. \n",
    "\n",
    ">- We do this because later we want to get an idea of how different pre-processing steps and models will perform on data it was not trained on. \n",
    ">- If we did this with our test set, we'd be tweeking our model to get better and better on this set and probably start to overfit to the specifics of this set (therefore its no longer a good measure of generalisation performance). \n",
    ">- Instead we are going to split our training data again and see how different models affect a validation set. \n",
    ">- We can use this validation set to guide pipeline changes with the comfort of knowing that when it comes time to assess our pipeline on our test set, that will give us a representative of generalisation performance as we'll only look at it right at the end.\n",
    "\n",
    "__Side Notes__\n",
    "- As you will learn about in future weeks, leaving your models on default parameters is generally a bad idea, but we'll do it for now until we understand the models more!\n",
    "- If your data is huge, you could subsample your training set here as well while checking different pre-processing and model steps (although this may penalize more complex models). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "minute-blame",
   "metadata": {
    "id": "minute-blame"
   },
   "outputs": [],
   "source": [
    "# Lets keep a copy for if we want them later\n",
    "X_train_full, y_train_full = X_train.copy(), y_train.copy()\n",
    "\n",
    "# Data splitting again over the training data now\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, # data to split\n",
    "                                                  test_size = 0.2,    # we will leave 20% to test our models on later\n",
    "                                                  random_state = 42,  # make our work reproducable \n",
    "                                                  shuffle = True)     # prevent data ordering affecting our model\n",
    "\n",
    "# Resetting the index values for both train and validation sets\n",
    "X_train = X_train.reset_index(drop = True)\n",
    "y_train = y_train.reset_index(drop = True)\n",
    "X_val = X_val.reset_index(drop = True)\n",
    "y_val = y_val.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mysterious-bronze",
   "metadata": {
    "id": "mysterious-bronze"
   },
   "source": [
    "Models in scikit-learn are _estimator_ classes. Like `resamplers` and `transformers` before them, estimators also have a `.fit()`. However, once the estimator is fitted, it can be used for predicting target values of new data using `.predict()`. This means you dont need to re-train the estimator each time you want to make a prediction.\n",
    "\n",
    "Therefore to model and predict values of a dataset, each  _estimator_ implements:\n",
    "\n",
    "```\n",
    "obj.fit(data)\n",
    "data_predictions = obj.predict(data)\n",
    "```\n",
    "\n",
    "or simply...\n",
    "\n",
    "```\n",
    "data_predictions = obj.fit_predict(data)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "negative-april",
   "metadata": {
    "id": "negative-april"
   },
   "source": [
    "---\n",
    "\n",
    "## 4.1. Regression\n",
    "\n",
    "Lets start with regression. You will probably already be familiar with the basics of regression. We'll be doing a recap and going deeper into linear and non-linear regression from a machine learning perspective at a later stage. We'll start by just fitting a basic linear regression model using `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "nonprofit-evolution",
   "metadata": {
    "id": "nonprofit-evolution"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunset-influence",
   "metadata": {
    "id": "sunset-influence"
   },
   "source": [
    "Great, now lets assess its performance. In later weeks we'll learn lots of different metrics (and learn its important to use more than just 1!), but for now we will just use Coefficient of Determination ($R^2$) which is the default.\n",
    "\n",
    "__What is $R^2$?__\n",
    "\n",
    "Without worrying about the details to much yet, it is a measure of the proportion of the variance in the dependent variable that is predictable from the independent variables and is the default scoring method for regression models in scikit-learn.\n",
    "\n",
    "__What is considered a good score?__\n",
    "\n",
    "Well it depends on the data but... \n",
    "- ...a value of 1.0, that means our model is perfectly fitting our data. \n",
    "- ...a value of 0.5 would mean that 50% of the variability in the outcome data is explained by the model.\n",
    "- ...ect.\n",
    "\n",
    "We could of course fit our model, make predictions, and calculate the $R^2$ ourselves or we could just use the `.score()` method. Lets start by having a look at how it did modelling our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "passive-frontier",
   "metadata": {
    "id": "passive-frontier"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.359"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(reg.score(X_train, y_train), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabulous-computer",
   "metadata": {
    "id": "fabulous-computer"
   },
   "source": [
    "So after rounding, we can explain 36% of the datas variability using this model. Lets start by checking the performance on the validation set to get an idea of its \"generalisation performance\".\n",
    "\n",
    "__Note__\n",
    "- If you get a different result than above you may have already altered the training data with pre-processing steps - don't do this yet... this is a task in a minute..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "intermediate-perry",
   "metadata": {
    "id": "intermediate-perry"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.268"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(reg.score(X_val, y_val), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "directed-salem",
   "metadata": {
    "id": "directed-salem"
   },
   "source": [
    "However in the validation set we can only explain 27% of the datas variability using this model. \n",
    "\n",
    "- This suggests our model is better at modelling our training data than our validation data. \n",
    "\n",
    "- This is common and would mean we should try tweek our model to reduce the difference between the training and validation performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "located-pencil",
   "metadata": {
    "id": "located-pencil"
   },
   "source": [
    "Another natural question is the following;\n",
    "\n",
    "What if our model wasn't learning anything? What $R^2$ score might we expect?\n",
    "\n",
    "- (optional) To check this you can fit a `DummyRegressor` (from `sklearn.dummy`), to the training data and assess its $R^2$ on the training and validation sets. How does it compare to the `LinearRegression` model? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "herbal-vienna",
   "metadata": {
    "id": "herbal-vienna"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score\n",
      "0.0\n",
      "Validation Score\n",
      "-0.015\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "dummy = DummyRegressor()\n",
    "dummy.fit(X_train, y_train)\n",
    "\n",
    "print(\"Training Score\")\n",
    "print(round(dummy.score(X_train, y_train), 3))\n",
    "print(\"Validation Score\")\n",
    "print(round(dummy.score(X_val, y_val), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5b14a9",
   "metadata": {},
   "source": [
    "- The dummy model that just predicts the mean would have a $R^2$ of 0 on the training set. This because $R^2$ is effectively just measuring how good the model is compared to a horizontal line, and that is all the dummy model is doing here with the data mean.\n",
    "\n",
    "- The validation score is a minus because, for this data, the mean of the training set is not as good a measure of the data variance as the mean of the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "native-turkish",
   "metadata": {
    "id": "native-turkish"
   },
   "source": [
    "---\n",
    "But wait we haven't used our pre-processing steps yet before feeding the data to the model! Lets remind ourselves of what our pre-processing steps are and then chain them together in a `Pipeline`. For the below one, only 4 steps are available, but 2 more can be added as you can realize from the lines of `lt = LogTransformer()` and `scaler = StandardScaler()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "vertical-humanitarian",
   "metadata": {
    "id": "vertical-humanitarian"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;drop_duplicated&#x27;,\n",
       "                 FunctionSampler(func=&lt;function drop_duplicated at 0x7fe422f63280&gt;,\n",
       "                                 validate=False)),\n",
       "                (&#x27;make_dataframe&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function DfTransformer at 0x7fe422fe04c0&gt;,\n",
       "                                     kw_args={&#x27;column_names&#x27;: [&#x27;fixed acidity&#x27;,\n",
       "                                                               &#x27;volatile &#x27;\n",
       "                                                               &#x27;acidity&#x27;,\n",
       "                                                               &#x27;citric acid&#x27;,\n",
       "                                                               &#x27;residual sugar&#x27;,\n",
       "                                                               &#x27;chlorides&#x27;,\n",
       "                                                               &#x27;free sulfur &#x27;\n",
       "                                                               &#x27;dioxide&#x27;,\n",
       "                                                               &#x27;total sulfur &#x27;\n",
       "                                                               &#x27;dioxide&#x27;,\n",
       "                                                               &#x27;density&#x27;, &#x27;pH&#x27;,\n",
       "                                                               &#x27;sulphates&#x27;,\n",
       "                                                               &#x27;alcohol&#x27;]})),\n",
       "                (&#x27;feature_selection&#x27;, DropCorrelatedFeatures(threshold=0.6)),\n",
       "                (&#x27;model&#x27;, LinearRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;drop_duplicated&#x27;,\n",
       "                 FunctionSampler(func=&lt;function drop_duplicated at 0x7fe422f63280&gt;,\n",
       "                                 validate=False)),\n",
       "                (&#x27;make_dataframe&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function DfTransformer at 0x7fe422fe04c0&gt;,\n",
       "                                     kw_args={&#x27;column_names&#x27;: [&#x27;fixed acidity&#x27;,\n",
       "                                                               &#x27;volatile &#x27;\n",
       "                                                               &#x27;acidity&#x27;,\n",
       "                                                               &#x27;citric acid&#x27;,\n",
       "                                                               &#x27;residual sugar&#x27;,\n",
       "                                                               &#x27;chlorides&#x27;,\n",
       "                                                               &#x27;free sulfur &#x27;\n",
       "                                                               &#x27;dioxide&#x27;,\n",
       "                                                               &#x27;total sulfur &#x27;\n",
       "                                                               &#x27;dioxide&#x27;,\n",
       "                                                               &#x27;density&#x27;, &#x27;pH&#x27;,\n",
       "                                                               &#x27;sulphates&#x27;,\n",
       "                                                               &#x27;alcohol&#x27;]})),\n",
       "                (&#x27;feature_selection&#x27;, DropCorrelatedFeatures(threshold=0.6)),\n",
       "                (&#x27;model&#x27;, LinearRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionSampler</label><div class=\"sk-toggleable__content\"><pre>FunctionSampler(func=&lt;function drop_duplicated at 0x7fe422f63280&gt;,\n",
       "                validate=False)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function DfTransformer at 0x7fe422fe04c0&gt;,\n",
       "                    kw_args={&#x27;column_names&#x27;: [&#x27;fixed acidity&#x27;,\n",
       "                                              &#x27;volatile acidity&#x27;, &#x27;citric acid&#x27;,\n",
       "                                              &#x27;residual sugar&#x27;, &#x27;chlorides&#x27;,\n",
       "                                              &#x27;free sulfur dioxide&#x27;,\n",
       "                                              &#x27;total sulfur dioxide&#x27;, &#x27;density&#x27;,\n",
       "                                              &#x27;pH&#x27;, &#x27;sulphates&#x27;, &#x27;alcohol&#x27;]})</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DropCorrelatedFeatures</label><div class=\"sk-toggleable__content\"><pre>DropCorrelatedFeatures(threshold=0.6)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('drop_duplicated',\n",
       "                 FunctionSampler(func=<function drop_duplicated at 0x7fe422f63280>,\n",
       "                                 validate=False)),\n",
       "                ('make_dataframe',\n",
       "                 FunctionTransformer(func=<function DfTransformer at 0x7fe422fe04c0>,\n",
       "                                     kw_args={'column_names': ['fixed acidity',\n",
       "                                                               'volatile '\n",
       "                                                               'acidity',\n",
       "                                                               'citric acid',\n",
       "                                                               'residual sugar',\n",
       "                                                               'chlorides',\n",
       "                                                               'free sulfur '\n",
       "                                                               'dioxide',\n",
       "                                                               'total sulfur '\n",
       "                                                               'dioxide',\n",
       "                                                               'density', 'pH',\n",
       "                                                               'sulphates',\n",
       "                                                               'alcohol']})),\n",
       "                ('feature_selection', DropCorrelatedFeatures(threshold=0.6)),\n",
       "                ('model', LinearRegression())])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn import set_config\n",
    "set_config(display='diagram')\n",
    "\n",
    "# remove duplicated values\n",
    "def drop_duplicated(X,y):\n",
    "    df = pd.concat([X,y], axis=1)\n",
    "    df = df.drop_duplicates()\n",
    "    return df.iloc[:,:-1], df.iloc[:,-1]\n",
    "\n",
    "DD =  FunctionSampler(func=drop_duplicated,\n",
    "                      validate=False)\n",
    "\n",
    "# Makes sure the data is a dataframe\n",
    "DT = FunctionTransformer(DfTransformer,\n",
    "                         kw_args = {\"column_names\":feature_names})\n",
    "\n",
    "# drops correlated features\n",
    "fs = DropCorrelatedFeatures(threshold=0.6)\n",
    "\n",
    "# log transforms all variables, assuming that Ex 11 is answered correctly\n",
    "# otherwise this part can be removed from the below pipeline \n",
    "# lt = LogTransformer()\n",
    "\n",
    "# standardises all variables, assuming that Ex 12 is answered correctly\n",
    "# otherwise this part can be removed from the below pipeline \n",
    "# scaler = StandardScaler() \n",
    "\n",
    "# here is the model we want to use.\n",
    "reg = LinearRegression()\n",
    "\n",
    "# create our pipeline for the data to go through.\n",
    "# This is a list of tuples with a name (useful later) and the function.\n",
    "reg_pipe = Pipeline([\n",
    "    (\"drop_duplicated\", DD),\n",
    "    (\"make_dataframe\", DT),\n",
    "    (\"feature_selection\", fs),\n",
    "    #(\"log_transformer\", lt), OPEN the comment if you have your LogTransformer from Ex 11\n",
    "    # (\"scaler\", scaler), OPEN the comment if you have your LogTransformer from Ex 12\n",
    "    (\"model\", reg)\n",
    "])\n",
    "\n",
    "reg_pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invalid-garden",
   "metadata": {
    "id": "invalid-garden"
   },
   "source": [
    "Lets see if this has improved performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "casual-mobility",
   "metadata": {
    "id": "casual-mobility"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score\n",
      "0.348\n",
      "Validation Score\n",
      "0.251\n"
     ]
    }
   ],
   "source": [
    "reg_pipe.fit(X_train, y_train)\n",
    "\n",
    "print(\"Training Score\")\n",
    "print(round(reg_pipe.score(X_train, y_train), 3))\n",
    "print(\"Validation Score\")\n",
    "print(round(reg_pipe.score(X_val, y_val), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southwest-filename",
   "metadata": {
    "id": "southwest-filename"
   },
   "source": [
    "...Okay so in this case maybe not. But we may be able to improve the pipeline by tuning it later. Maybe we don't need all these steps, or maybe there are better models to use? Lets look at different models to start with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "front-glass",
   "metadata": {
    "id": "front-glass"
   },
   "source": [
    "---\n",
    "\n",
    "###  Exercise 14 (EXTRA)\n",
    "\n",
    "See if other regression models can be used to improve performance.\n",
    "\n",
    "a) create a `pipeline` with `PolynomialFeatures(include_bias=False)` in between the `\"log_transformer\"` and `\"scaler\"`.\n",
    "\n",
    "__Note__\n",
    "\n",
    "- `PolynomialFeatures()` enables our regression model to capture \"non-linear\" relationships between our variables (we'll look at this more next week).\n",
    "- `include_bias=False` just stops the function ading a bias column as our `LinearRegression` object is going to add one for us anyway.\n",
    "\n",
    "You can try to benefit from the following source:\n",
    "\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "opponent-dinner",
   "metadata": {
    "id": "opponent-dinner"
   },
   "outputs": [],
   "source": [
    "# Necessary module from sklearn \n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informational-pilot",
   "metadata": {
    "id": "informational-pilot"
   },
   "source": [
    "b) create a different `pipeline` with `DecisionTreeRegressor()` used instead of the `LinearRegression` model.\n",
    "\n",
    "__Note__\n",
    "- This time you don't want to have `PolynomialFeatures()`.\n",
    "\n",
    "You can try to benefit from the following source:\n",
    "\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "amber-lloyd",
   "metadata": {
    "id": "amber-lloyd"
   },
   "outputs": [],
   "source": [
    "# Necessary module from sklearn\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "departmental-worcester",
   "metadata": {
    "id": "departmental-worcester"
   },
   "source": [
    "c) How do these models compare to the standard `LinearRegression` pipeline according to their $R^2$ performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finnish-secondary",
   "metadata": {
    "id": "finnish-secondary"
   },
   "source": [
    "---\n",
    "You may be thinking, well I could have done all that without bothering with making sure my functions were compatible with a `Pipeline`. There are two main reasons why we suggest using them:\n",
    "\n",
    "__Ensures Information Bleed Prevention__\n",
    "\n",
    "- If we did all our preprocessing steps before splitting the data into training and validation steps, we would bleed information from our validation set for training the models. For example, we scaled our features which requires us taking a mean and standard deviation of the data we'll train our model on. If these means and standard deviations include the data we will use for validation they may very slightly improve our result and then when we later make predictions on the test set we may find performance is slightly worse than expected as we truely did not use any information from that set! \n",
    "\n",
    "- Over time these small amounts of information bleed may add up and mean our validation set is no longer as useful assessing how our model performs on other data.\n",
    "\n",
    "So did this effect us because we did pre-processing steps before splitting our data? \n",
    "**Nope because we use pipelines.** \n",
    "\n",
    "- When we used `.fit(X_train, y_train)` as above, this overwrites the parameters of the pre-processing steps and the model so we can be assured this only reflects information from this set. \n",
    "\n",
    "- Sure you could go step by step using `.fit_transform()` on your data and passing the output to the next function, but this would not be as simple as putting them all in a `Pipeline`. \n",
    "\n",
    "- Another way round would be to split your data into training and validation sets before pre-processing your data to stop you needing to re-fit your pre-processing steps later. This would work, but using a `Pipeline` works well with other validation methods too (so saves us some additional coding).\n",
    "\n",
    "__Works well with Different Validation Methods__\n",
    "\n",
    "Heres where `Pipelines` really start to get useful (and we'll see more extensions of this over the coming weeks). \n",
    "\n",
    "- So far we've used the `train_test_split` function to split the training set into a smaller training set and a validation set, which we have used to validate our models. \n",
    "\n",
    "- This works well, but by partitioning the available data into three sets, we reduce the number of samples that can be used for learning the model, and the results depend on the random choice of the pair of (train, validation) sets. \n",
    "\n",
    "- A great alternative is therefore to use Scikit-Learns `_K-fold cross-validation_` feature. A test set should still be held out for final evaluation, but **the validation set is no longer needed when doing CV**. \n",
    "\n",
    "When doing **k-fold cross-validation**, the training set is split into $k$ smaller sets and:\n",
    "\n",
    "- A model is trained using $k-1$ of the folds as training data.\n",
    "\n",
    "- The resulting model is validated on the remaining part of the data.\n",
    "\n",
    "The performance measure reported by k-fold cross-validation is therefore the average of the values computed in the loop. Although more computationally expensive than a single split, it does not waste too much data (particularly useful when the number of samples is very small) and gives us more robust assessment of performance. Don't worry if you are stuggling to understand what is k-fold cross-validation as we will introduce them next week in detail. \n",
    "\n",
    "Again, using a `Pipeline` with this method will ensure there is no information bleed between our different folds. Lets have a look how we could evaluate our initial linear regression pipeline below with them.\n",
    "\n",
    "__Note__\n",
    "- You can use `cross_val_score` if you just want the validation score.\n",
    "- Note `cross_validate` calls the validation performance the `test_score`, to be clear this is the validation performance and should not be used as \"test\"! This is why I rename it in the `tidy_scores` function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "successful-homeless",
   "metadata": {
    "id": "successful-homeless"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>val_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sd</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fit_time  score_time  val_score  train_score\n",
       "fold                                              \n",
       "0         0.01         0.0       0.24         0.35\n",
       "1         0.01         0.0       0.29         0.34\n",
       "2         0.01         0.0       0.27         0.34\n",
       "3         0.01         0.0       0.34         0.33\n",
       "4         0.01         0.0       0.44         0.31\n",
       "mean      0.01         0.0       0.32         0.34\n",
       "sd        0.00         0.0       0.07         0.02"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# tidy the output into a dataframe\n",
    "def tidy_scores(score_dict):\n",
    "    df = pd.DataFrame(score_dict)\n",
    "    df.loc['mean'] = df.mean()\n",
    "    df.loc['sd'] = df.std()\n",
    "    df.rename({\"test_score\":\"val_score\"}, axis=1, inplace=True)\n",
    "    df.index.name = \"fold\"\n",
    "    return df.round(2)\n",
    "\n",
    "scores = cross_validate(reg_pipe, X_train_full, y_train_full, cv=5, return_train_score=True)\n",
    "tidy_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clinical-syndication",
   "metadata": {
    "id": "clinical-syndication"
   },
   "source": [
    "---\n",
    "\n",
    "###  Exercise 15 (EXTRA)\n",
    "\n",
    "Assess the performance of the other regression pipelines made above (one with `PolynomialFeatures(include_bias=False)` and the other with a `DecisionTreeRegressor`) using `cross_validate`. \n",
    "- Do these results change your intepretation of the best model pipeline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "remarkable-redhead",
   "metadata": {
    "id": "remarkable-redhead"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "intensive-ontario",
   "metadata": {
    "id": "intensive-ontario"
   },
   "source": [
    "---\n",
    "At this point you would normally begin to examine how the fitted models are working and what are the most most useful variables for each algorithm. Investigating this may give you a deeper insight into the data and inform another quick round of feature selection and engineering. However, for now we are just going to skip this until we learn more about the models on the course."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affiliated-newton",
   "metadata": {
    "id": "affiliated-newton"
   },
   "source": [
    "---\n",
    "# 5. Summary <a id='sum'></a>\n",
    "\n",
    "For the sake of this workshop, you are now roughly done. We will be going over a lot of this stuff over the rest of the course, so don't worry if there are areas you want more information on. However hopefully you feel we have addressed the aim of getting an overview of how a typical machine learning project looks like.\n",
    "\n",
    "- This workshop we worked through a number of the steps required as part of a machine learning project. \n",
    "\n",
    "- We were introduced to scikit-learn and specifically how to use a `pipeline` to string multiple steps together. \n",
    "\n",
    "- It may seem like unneccesary extra work, but as we introduce more complex methods, they will become incredibly useful and save time.\n",
    "\n",
    "- However, still, we may proceed by using different paths regarding the problem at hand instead of `pipeline` idea. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Vs9w1LNnvCGo",
   "metadata": {
    "id": "Vs9w1LNnvCGo"
   },
   "source": [
    "# 6. What Else ? <a id='extra'></a>\n",
    "\n",
    "Remember that the our data wine data set has a response, 'quality' of the red wine. Just for the illustration, we fit a linear regression model above to start with but we did not say anything about whether the tyep of response is suitable or not. If you have a look at your response variable, you will see that it is actually a categorical variable to represent different quality levels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "16b092f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    426\n",
       "6    413\n",
       "7    131\n",
       "4     33\n",
       "8     11\n",
       "3      9\n",
       "Name: quality, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738640da",
   "metadata": {},
   "source": [
    "- Although, fitting linear regression is computationally possible, the output itself indeed is missing regarding the response type at hand. \n",
    "\n",
    "- Since it includes different categories of wine quality, we need to treat it as a categorical variable before fitting any model. \n",
    "\n",
    "- Certainly, this impacts the model that we need to search for. Below are extra information about possible further steps in the model development process and additional tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chemical-zoning",
   "metadata": {
    "id": "chemical-zoning"
   },
   "source": [
    "---\n",
    "\n",
    "## Classification\n",
    "\n",
    "As we mentioned above, our response is a categorical variable having 6 different categories at the beginning. For the sake of simplicity, lets change the output variable to a binary output (0 or 1) and have a look at some classification models.\n",
    "\n",
    "__Note__\n",
    "- You may be wondering if you could turn this into a function and add this into a `Pipeline` using the `FunctionSampler`. As far as I can tell you can't because samplers are _only_ applied when fitting (training) the model, and not when making predictions. We need our labels to be changed in this binary way for both fitting the model and making predictions - so we do this before putting it though our pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "matched-contrary",
   "metadata": {
    "id": "matched-contrary"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3      9\n",
       "4     33\n",
       "5    426\n",
       "6    413\n",
       "7    131\n",
       "8     11\n",
       "Name: quality, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    881\n",
       "1    142\n",
       "Name: quality, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "replace_dict = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:1, 8:1, 9:1, 10:1}\n",
    "\n",
    "y_train_ = y_train.replace(replace_dict)\n",
    "y_val_ = y_val.replace(replace_dict)\n",
    "\n",
    "display(y_train.value_counts().sort_index())\n",
    "display(y_train_.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bf4e45",
   "metadata": {},
   "source": [
    "When we look at the frequencies of the binary outputs (counts on 0 and 1 values), we still have \"imballanced\" data which will likely affect our model performance but lets not worry about that for now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "devoted-republican",
   "metadata": {
    "id": "devoted-republican"
   },
   "source": [
    "---\n",
    "\n",
    "###  Exercise 16 (EXTRA)\n",
    "\n",
    "Using the following pipeline workflow (`\"drop_duplicated\"`, `\"feature_selection\"`, `\"log_transformer\"`, `\"scaler\"`, `\"model\"`), assess the training and validation set performance of the following models (on their default settings):\n",
    "- `DummyClassifier` (https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html)\n",
    "- `LogisticRegression` (https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
    "- `KNeighborsClassifier` (https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)\n",
    "\n",
    "__Note__\n",
    "- Using the `.score()` method on classification models defaults to \"Accuracy\". \n",
    "    - Put simply, Accuracy is just: correct predictions / total predictions * 100.0. \n",
    "    - Like `R^2` in regression, we want this to be high (close to 1). \n",
    "    - Like regression we will examine classification performance metrics in much more detail over the rest of the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decimal-relative",
   "metadata": {
    "id": "decimal-relative"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fitting-federation",
   "metadata": {
    "id": "fitting-federation"
   },
   "source": [
    "---\n",
    "\n",
    "## About Model Refinement\n",
    "\n",
    "Now you will want to fine-tune your models. \n",
    "\n",
    "- Normally you would select a couple of models which are making different errors to examine in more detail but for the sake of this workshop we are just going to look at the best regression (Linear Regression) and classifier (K-Nearest-Neighbors) models.\n",
    "\n",
    "- To fine tune your model you want to change your models \"hyperparameters\". \n",
    "\n",
    "- At the moment we have mostly been using each model on their default parameters, but most have settings we can change. However, as we haven't explained any of these models yet we are going to leave these on default. \n",
    "\n",
    "- Instead we are going to try improve model performance by changing our data transformations (we'll be looking at this in more detail next week as well)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "buried-wealth",
   "metadata": {
    "id": "buried-wealth"
   },
   "source": [
    "---\n",
    "Remove and/or change some of the pre-processing steps to see if you can improve both the \"best\" regression and classification model performance*. Here are some things you can try:\n",
    "\n",
    "- Remove the duplicated observations/feature selection/transformer/scaling step from the pipeline.\n",
    "- Change the `threshold` for the `DropCorrelatedFeatures`.\n",
    "\n",
    "__Notes__\n",
    "- Instead of deleting or hashing out a pipeline step you want to skip, you can specify the name string as `\"passthrough\"` or set the resampler/transformer/estimator to `None`. This is useful later in the course when we get onto using automated methods to refine our models.\n",
    "\n",
    "*_At the moment we are going to do this all manually, but in the coming weeks you will learn how to automate this process._\n",
    "\n",
    "To give a simple example, consider the following pipeline with changed threshold value for the `DropCorrelatedFeatures`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "19003f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score\n",
      "0.358\n",
      "Validation Score\n",
      "0.27\n"
     ]
    }
   ],
   "source": [
    "# remove duplicated values\n",
    "def drop_duplicated(X,y):\n",
    "    df = pd.concat([X,y], axis=1)\n",
    "    df = df.drop_duplicates()\n",
    "    return df.iloc[:,:-1], df.iloc[:,-1]\n",
    "\n",
    "DD =  FunctionSampler(func=drop_duplicated,\n",
    "                      validate=False)\n",
    "\n",
    "# Makes sure the data is a dataframe\n",
    "DT = FunctionTransformer(DfTransformer,\n",
    "                         kw_args = {\"column_names\":feature_names})\n",
    "\n",
    "# drops correlated features\n",
    "fs = DropCorrelatedFeatures(threshold=0.75)\n",
    "\n",
    "# here is the model we want to use.\n",
    "reg = LinearRegression()\n",
    "\n",
    "# create our pipeline for the data to go through.\n",
    "# This is a list of tuples with a name (useful later) and the function.\n",
    "reg_pipe = Pipeline([\n",
    "    (\"drop_duplicated\", DD),\n",
    "    (\"make_dataframe\", DT),\n",
    "    (\"feature_selection\", fs),\n",
    "    (\"model\", reg)\n",
    "])\n",
    "\n",
    "reg_pipe.fit(X_train, y_train)\n",
    "\n",
    "print(\"Training Score\")\n",
    "print(round(reg_pipe.score(X_train, y_train), 3))\n",
    "print(\"Validation Score\")\n",
    "print(round(reg_pipe.score(X_val, y_val), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243a560e",
   "metadata": {},
   "source": [
    "It seems that the increase on the `threshold` avoid collinearity issue more, and this has a positive impact on the model performance over train and validation test. Since the value of Coefficient of Determination ($R^2$) is increased for both data sets. \n",
    "\n",
    "What about the perfomance of the model on the *test set* ? For this calculation, we need;\n",
    "\n",
    "- Prediction of the fitted model using the given feature values under test data (like a new data set)\n",
    "\n",
    "- Comparison of the difference between the original response values stored in the test data and predicted response values coming from the above-fitted linear model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a5025b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320, 11)\n",
      "(320,)\n",
      "Test Score\n",
      "0.41\n"
     ]
    }
   ],
   "source": [
    "y_test = test_df.loc[:, output]\n",
    "X_test = test_df.drop(output, axis=1)\n",
    "\n",
    "feature_names = list(X_train.columns)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "print(\"Test Score\")\n",
    "print(round(reg_pipe.score(X_test, y_test), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatty-channels",
   "metadata": {
    "id": "fatty-channels"
   },
   "source": [
    "---\n",
    "## Presentation and Deployment\n",
    "\n",
    "Now with your models are complete you would present your findings in a report worded appropriately for the intended audience (e.g. business people, statistician, engineer). \n",
    "\n",
    "- Here is where you may improve your visualisations and present your findings in an interesting way.\n",
    "\n",
    "- Part of this is getting a final assessment of the generalisation performance for your final models to present (what the test set is for). \n",
    "\n",
    "- The reason we leave it so late is because it is important that you do not tweak your model after doing this as this will mean that you would just start to overfit to your test set! Overfitting is the reason at this point that your model may perform better on the training and validation sets than the test set. \n",
    "\n",
    "- If so, don't worry too much (its to be expected), we'll be learning a few other techniques to reduce this over the semester."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleasant-cheese",
   "metadata": {
    "id": "pleasant-cheese"
   },
   "source": [
    "---\n",
    ">- It maybe that your model is going to be adopted into practice. At this point, depending on your skills, you may work with an engineer to get your code production ready (e.g. impliment unit tests, performance and input monitoring, retraining secedules), or if your better at coding just do it yourself.\n",
    ">- In this case you can provide your client a model that when they input properties of a wine it predicts the \"quality\" of the wine. This could be used to help guide the clients on how to price the wine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pacific-robinson",
   "metadata": {
    "id": "pacific-robinson"
   },
   "source": [
    "---\n",
    "\n",
    "###  Exercise 17 (SELF-STUDY)\n",
    "\n",
    "If you are feeling extra keen;\n",
    "\n",
    "- Why not do the above process again with the white wine dataset. \n",
    "\n",
    "- Are your results similar or different? \n",
    "\n",
    "Maybe you want to come back to this after learning a bit more on the course. Its entirely up to you and could be a good practice for your self-study. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "distant-seminar",
   "metadata": {
    "id": "distant-seminar"
   },
   "outputs": [],
   "source": [
    "df_white = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\",\n",
    "                       delimiter=\";\")\n",
    "\n",
    "#df_white.head()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "buried-wealth"
   ],
   "name": "week01.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0b4b84a2d3c9414f8370cd25cba1db37": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "64bf9c83fafd43f78ead0dcc2b6dc117": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ButtonView",
      "button_style": "",
      "description": "Hide solution",
      "disabled": false,
      "icon": "",
      "layout": "IPY_MODEL_8600f40a5c614e5aa63e874ddb32553f",
      "style": "IPY_MODEL_0b4b84a2d3c9414f8370cd25cba1db37",
      "tooltip": ""
     }
    },
    "798d7fe68b8340c59a2e4c8225c6396d": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_7d3e884f4d2449dea509ee7b7d2cb24b",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<style>.output_html .hll { background-color: #ffffcc }\n.output_html  { background: #f8f8f8; }\n.output_html .c { color: #408080; font-style: italic } /* Comment */\n.output_html .err { border: 1px solid #FF0000 } /* Error */\n.output_html .k { color: #008000; font-weight: bold } /* Keyword */\n.output_html .o { color: #666666 } /* Operator */\n.output_html .ch { color: #408080; font-style: italic } /* Comment.Hashbang */\n.output_html .cm { color: #408080; font-style: italic } /* Comment.Multiline */\n.output_html .cp { color: #BC7A00 } /* Comment.Preproc */\n.output_html .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */\n.output_html .c1 { color: #408080; font-style: italic } /* Comment.Single */\n.output_html .cs { color: #408080; font-style: italic } /* Comment.Special */\n.output_html .gd { color: #A00000 } /* Generic.Deleted */\n.output_html .ge { font-style: italic } /* Generic.Emph */\n.output_html .gr { color: #FF0000 } /* Generic.Error */\n.output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n.output_html .gi { color: #00A000 } /* Generic.Inserted */\n.output_html .go { color: #888888 } /* Generic.Output */\n.output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n.output_html .gs { font-weight: bold } /* Generic.Strong */\n.output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n.output_html .gt { color: #0044DD } /* Generic.Traceback */\n.output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n.output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n.output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n.output_html .kp { color: #008000 } /* Keyword.Pseudo */\n.output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n.output_html .kt { color: #B00040 } /* Keyword.Type */\n.output_html .m { color: #666666 } /* Literal.Number */\n.output_html .s { color: #BA2121 } /* Literal.String */\n.output_html .na { color: #7D9029 } /* Name.Attribute */\n.output_html .nb { color: #008000 } /* Name.Builtin */\n.output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n.output_html .no { color: #880000 } /* Name.Constant */\n.output_html .nd { color: #AA22FF } /* Name.Decorator */\n.output_html .ni { color: #999999; font-weight: bold } /* Name.Entity */\n.output_html .ne { color: #D2413A; font-weight: bold } /* Name.Exception */\n.output_html .nf { color: #0000FF } /* Name.Function */\n.output_html .nl { color: #A0A000 } /* Name.Label */\n.output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n.output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n.output_html .nv { color: #19177C } /* Name.Variable */\n.output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n.output_html .w { color: #bbbbbb } /* Text.Whitespace */\n.output_html .mb { color: #666666 } /* Literal.Number.Bin */\n.output_html .mf { color: #666666 } /* Literal.Number.Float */\n.output_html .mh { color: #666666 } /* Literal.Number.Hex */\n.output_html .mi { color: #666666 } /* Literal.Number.Integer */\n.output_html .mo { color: #666666 } /* Literal.Number.Oct */\n.output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n.output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n.output_html .sc { color: #BA2121 } /* Literal.String.Char */\n.output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n.output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n.output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n.output_html .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */\n.output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n.output_html .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */\n.output_html .sx { color: #008000 } /* Literal.String.Other */\n.output_html .sr { color: #BB6688 } /* Literal.String.Regex */\n.output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n.output_html .ss { color: #19177C } /* Literal.String.Symbol */\n.output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n.output_html .fm { color: #0000FF } /* Name.Function.Magic */\n.output_html .vc { color: #19177C } /* Name.Variable.Class */\n.output_html .vg { color: #19177C } /* Name.Variable.Global */\n.output_html .vi { color: #19177C } /* Name.Variable.Instance */\n.output_html .vm { color: #19177C } /* Name.Variable.Magic */\n.output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"n\">sns</span><span class=\"o\">.</span><span class=\"n\">set</span><span class=\"p\">(</span><span class=\"n\">rc</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">&#39;figure.figsize&#39;</span><span class=\"p\">:</span> <span class=\"p\">(</span><span class=\"mi\">14</span><span class=\"p\">,</span> <span class=\"mi\">8</span><span class=\"p\">)})</span> \n<span class=\"n\">sns</span><span class=\"o\">.</span><span class=\"n\">countplot</span><span class=\"p\">(</span><span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">y_train</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">title</span><span class=\"p\">(</span><span class=\"s2\">&quot;Figure 1. Quality of the wine&quot;</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">show</span><span class=\"p\">()</span>\n</pre></div>\n",
         "text/latex": "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n\\PY{n}{sns}\\PY{o}{.}\\PY{n}{set}\\PY{p}{(}\\PY{n}{rc}\\PY{o}{=}\\PY{p}{\\PYZob{}}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{figure.figsize}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{:} \\PY{p}{(}\\PY{l+m+mi}{14}\\PY{p}{,} \\PY{l+m+mi}{8}\\PY{p}{)}\\PY{p}{\\PYZcb{}}\\PY{p}{)} \n\\PY{n}{sns}\\PY{o}{.}\\PY{n}{countplot}\\PY{p}{(}\\PY{n}{x} \\PY{o}{=} \\PY{n}{y\\PYZus{}train}\\PY{p}{)}\n\\PY{n}{plt}\\PY{o}{.}\\PY{n}{title}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{Figure 1. Quality of the wine}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n\\PY{n}{plt}\\PY{o}{.}\\PY{n}{show}\\PY{p}{(}\\PY{p}{)}\n\\end{Verbatim}\n",
         "text/plain": "sns.set(rc={'figure.figsize': (14, 8)}) \nsns.countplot(x = y_train)\nplt.title(\"Figure 1. Quality of the wine\")\nplt.show()"
        },
        "metadata": {},
        "output_type": "display_data"
       },
       {
        "data": {
         "text/markdown": "It appears the majority of wine is of medium quality, with there being much less poor (3 & 4) and good (7 & 8) quality wine.\n",
         "text/plain": "<IPython.core.display.Markdown object>"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    },
    "7d3e884f4d2449dea509ee7b7d2cb24b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": "1px solid green",
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8600f40a5c614e5aa63e874ddb32553f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
