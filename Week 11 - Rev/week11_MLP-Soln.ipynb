{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 11 - Review and Beyond MLP\n",
    "\n",
    "### Aims\n",
    "\n",
    "By the end of this notebook you will be able to understand \n",
    "\n",
    ">* The Basics of Keras overview\n",
    ">* Linear Regression by Keras\n",
    ">* Working out on Project II data\n",
    "\n",
    "The exercises here are designed to reinforce the basics of keras for further use. Additionally, you will see some simple tasks to try and comment out. \n",
    "\n",
    "- For the last time, you will have lighter tasks tagged by (CORE) and (EXTRA).\n",
    "\n",
    "- If you already submitted at least 5 hands-in script before (marked as 1), you can directly start your project II during the WS. \n",
    "\n",
    "- Some experiments asked below is related to the hotel data already. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hm6XqPScK-FV"
   },
   "source": [
    "# Imports\n",
    "\n",
    "We're only going to need a couple of standard libraries this week, as well as keras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display plots inline\n",
    "%matplotlib inline  \n",
    "\n",
    "# Data libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "usEZAe6SYpV8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-03 17:57:22.079223: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-03 17:57:22.528109: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-04-03 17:57:22.528145: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-04-03 17:57:22.583511: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-04-03 17:57:24.244973: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-03 17:57:24.245098: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-03 17:57:24.245111: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/opt/conda/lib/python3.9/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (5.0.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-643694a4bf05b764\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-643694a4bf05b764\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 5036;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Not necessary in general !\n",
    "import os, datetime\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "%load_ext tensorboard\n",
    "%tensorboard --port=5036 --logdir $logdir\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(logdir, histogram_freq=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qeHcm_OBGhtx"
   },
   "source": [
    "# Basics\n",
    "\n",
    "**Just to highlight some differences**\n",
    "\n",
    "TensorFlow is an infrastructure layer for differentiable programming. At its heart, it's a framework for manipulating N-dimensional arrays (tensors), much like NumPy.But as you experienced already, there are three key differences between NumPy and TensorFlow:\n",
    "\n",
    "- TensorFlow can leverage hardware accelerators such as GPUs and TPUs.\n",
    "\n",
    "- TensorFlow can automatically compute the gradient of arbitrary differentiable tensor expressions.\n",
    "\n",
    "- TensorFlow computation can be distributed to large numbers of devices on a single machine, and large number of machines (potentially with multiple devices each)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "NZw0Lb1wR395"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[5 2]\n",
      " [1 3]], shape=(2, 2), dtype=int32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-03 17:57:49.507482: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-04-03 17:57:49.507535: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-04-03 17:57:49.507562: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (noteable): /proc/driver/nvidia/version does not exist\n",
      "2023-04-03 17:57:49.510694: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[5, 2], [1, 3]])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 2],\n",
       "       [1, 3]], dtype=int32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can get its value as a NumPy array by calling .numpy():\n",
    "x.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtype: <dtype: 'int32'>\n",
      "shape: (2, 2)\n"
     ]
    }
   ],
   "source": [
    "# Much like a NumPy array, it features the attributes dtype and shape:\n",
    "print(\"dtype:\", x.dtype)\n",
    "print(\"shape:\", x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[ 3.0926309,  1.0278603],\n",
       "       [-1.1365403,  0.7284249]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can also create random constant tensors:\n",
    "x = tf.random.normal(shape=(2, 2), mean=0.0, stddev=1.0)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables\n",
    "\n",
    "Variables are special tensors used to store mutable state (such as the weights of a neural network). You create a Variable using some initial value:\n",
    "\n",
    "**Doing math in TensorFlow:** \n",
    "\n",
    "If you've used NumPy, doing math in TensorFlow will look very familiar. The main difference is that your TensorFlow code can run on GPU and TPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
      "array([[ 1.7980986 ,  0.15745784],\n",
      "       [-0.6098922 , -2.0456643 ]], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "initial_value = tf.random.normal(shape=(2, 2))\n",
    "a = tf.Variable(initial_value)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-1.8071861  1.251079 ]\n",
      " [-2.850041   1.2538288]], shape=(2, 2), dtype=float32) tf.Tensor(\n",
      "[[3.2659216 1.5651985]\n",
      " [8.122733  1.5720866]], shape=(2, 2), dtype=float32) tf.Tensor(\n",
      "[[  26.20425      4.7836246]\n",
      " [3370.2195       4.816688 ]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.random.normal(shape=(2, 2))\n",
    "b = tf.random.normal(shape=(2, 2))\n",
    "\n",
    "c = a + b\n",
    "d = tf.square(c)\n",
    "e = tf.exp(d)\n",
    "print(c, d, e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5q1xG24emmdu"
   },
   "source": [
    "# Exercise 1 (CORE)\n",
    "\n",
    "You can convert a the dataframe column to a tensor object like so: `tf.constant((df['column_name']))`\n",
    "\n",
    "So, consider your hotel data set as data frame;\n",
    "\n",
    "- Convert the numerical variables `lead_time` and `adr` into tensor object\n",
    "\n",
    "- Print the shape and type of created tensor objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_canceled</th>\n",
       "      <th>hotel</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>arrival_date_year</th>\n",
       "      <th>arrival_date_month</th>\n",
       "      <th>arrival_date_week_number</th>\n",
       "      <th>arrival_date_day_of_month</th>\n",
       "      <th>stays_in_weekend_nights</th>\n",
       "      <th>stays_in_week_nights</th>\n",
       "      <th>adults</th>\n",
       "      <th>...</th>\n",
       "      <th>assigned_room_type</th>\n",
       "      <th>booking_changes</th>\n",
       "      <th>deposit_type</th>\n",
       "      <th>agent</th>\n",
       "      <th>company</th>\n",
       "      <th>days_in_waiting_list</th>\n",
       "      <th>customer_type</th>\n",
       "      <th>adr</th>\n",
       "      <th>required_car_parking_spaces</th>\n",
       "      <th>total_of_special_requests</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>342</td>\n",
       "      <td>2015</td>\n",
       "      <td>July</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>737</td>\n",
       "      <td>2015</td>\n",
       "      <td>July</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>4</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>7</td>\n",
       "      <td>2015</td>\n",
       "      <td>July</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>13</td>\n",
       "      <td>2015</td>\n",
       "      <td>July</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>304.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>14</td>\n",
       "      <td>2015</td>\n",
       "      <td>July</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>240.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_canceled         hotel  lead_time  arrival_date_year arrival_date_month  \\\n",
       "0            0  Resort Hotel        342               2015               July   \n",
       "1            0  Resort Hotel        737               2015               July   \n",
       "2            0  Resort Hotel          7               2015               July   \n",
       "3            0  Resort Hotel         13               2015               July   \n",
       "4            0  Resort Hotel         14               2015               July   \n",
       "\n",
       "   arrival_date_week_number  arrival_date_day_of_month  \\\n",
       "0                        27                          1   \n",
       "1                        27                          1   \n",
       "2                        27                          1   \n",
       "3                        27                          1   \n",
       "4                        27                          1   \n",
       "\n",
       "   stays_in_weekend_nights  stays_in_week_nights  adults  ...  \\\n",
       "0                        0                     0       2  ...   \n",
       "1                        0                     0       2  ...   \n",
       "2                        0                     1       1  ...   \n",
       "3                        0                     1       1  ...   \n",
       "4                        0                     2       2  ...   \n",
       "\n",
       "   assigned_room_type  booking_changes deposit_type  agent company  \\\n",
       "0                   C                3   No Deposit    NaN     NaN   \n",
       "1                   C                4   No Deposit    NaN     NaN   \n",
       "2                   C                0   No Deposit    NaN     NaN   \n",
       "3                   A                0   No Deposit  304.0     NaN   \n",
       "4                   A                0   No Deposit  240.0     NaN   \n",
       "\n",
       "  days_in_waiting_list  customer_type   adr  required_car_parking_spaces  \\\n",
       "0                    0      Transient   0.0                            0   \n",
       "1                    0      Transient   0.0                            0   \n",
       "2                    0      Transient  75.0                            0   \n",
       "3                    0      Transient  75.0                            0   \n",
       "4                    0      Transient  98.0                            0   \n",
       "\n",
       "  total_of_special_requests  \n",
       "0                         0  \n",
       "1                         0  \n",
       "2                         0  \n",
       "3                         0  \n",
       "4                         1  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the data set\n",
    "df_hotel = pd.read_csv(\"hotel.csv\")\n",
    "\n",
    "df_hotel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "X = df_hotel['lead_time']\n",
    "y = df_hotel['adr']\n",
    "\n",
    "\n",
    "# Checking the missing values\n",
    "print(X.isnull().sum())\n",
    "print(y.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([342 737   7 ...  34 109 205], shape=(119390,), dtype=int64)\n",
      "tf.Tensor([  0.     0.    75.   ... 157.71 104.4  151.2 ], shape=(119390,), dtype=float64)\n",
      "dtype: <dtype: 'int64'> <dtype: 'float64'>\n",
      "shape: (119390,) (119390,)\n"
     ]
    }
   ],
   "source": [
    "# For the conversion\n",
    "X = tf.constant((X))\n",
    "y = tf.constant((y))\n",
    "\n",
    "print(X)\n",
    "print(y)\n",
    "\n",
    "# For the details on the created tensors\n",
    "# Much like a NumPy array, it features the attributes dtype and shape:\n",
    "print(\"dtype:\", X.dtype, y.dtype)\n",
    "print(\"shape:\", y.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nCExrjAlmQOm"
   },
   "source": [
    "# Keras layers\n",
    "\n",
    "You already experienced by directly applying some layers in Week 9-10 but let us recall once again some properties\n",
    "\n",
    "- While TensorFlow is an infrastructure layer for differentiable programming, dealing with tensors, variables, and gradients, Keras is a user interface for deep learning, dealing with layers, models, optimizers, loss functions, metrics, and more.\n",
    "\n",
    "- Keras serves as the high-level API for TensorFlow: Keras is what makes TensorFlow simple and productive.\n",
    "\n",
    "- The Layer class is the fundamental abstraction in Keras. A Layer encapsulates a state (weights) and some computation (defined in the call method).\n",
    "\n",
    "A simple layer looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(keras.layers.Layer):\n",
    "    \"\"\"y = w.x + b\"\"\"\n",
    "\n",
    "    def __init__(self, units=32, input_dim=32):\n",
    "        super().__init__()\n",
    "        w_init = tf.random_normal_initializer()\n",
    "        self.w = tf.Variable(\n",
    "            initial_value=w_init(shape=(input_dim, units), dtype=\"float32\"),\n",
    "            trainable=True,\n",
    "        )\n",
    "        b_init = tf.zeros_initializer()\n",
    "        self.b = tf.Variable(\n",
    "            initial_value=b_init(shape=(units,), dtype=\"float32\"), trainable=True\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Linear at 0x7f4cd2faec70>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You would use a Layer instance much like a Python function:\n",
    "linear_layer = Linear(units=4, input_dim=2)\n",
    "linear_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 4), dtype=float32, numpy=\n",
       "array([[-0.00755919, -0.07351511,  0.0961083 , -0.05432985],\n",
       "       [-0.00755919, -0.07351511,  0.0961083 , -0.05432985]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The layer can be treated as a function.\n",
    "# Here we call it on some data.\n",
    "t = linear_layer(tf.ones((2, 2)))\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9R_1TGs8rInz"
   },
   "source": [
    "# Exercise 2 (CORE)\n",
    "\n",
    "Consider the class definition given above for the `Linear` one \n",
    "\n",
    "- Explain the each line of code to demistfy the meaning of this class, `Linear`\n",
    "\n",
    "- Discuss the meaning of `Linear(units=4, input_dim=2)` usage above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HhzuQdIuptAh"
   },
   "source": [
    "Basically, that function creates a linear class of layers bu calling `__init__` and `call` functions inside of this. If we look at the components of it closely \n",
    "\n",
    "- It is a densely-connected layer having the state: the variables w and b. The goal is creating a linear combination of x.\n",
    "\n",
    "- `tf.random_normal_initializer()` stands for the Initializer that generates tensors with a normal distribution having mean=0.0, stddev=0.05 values by default\n",
    "\n",
    "- Creation of `self.w` variable via the `tf.Variable` class, with `trainable=True` where GradientTapes automatically watch uses of this variable\n",
    "\n",
    "- `tf.zeros_initializer()` stands for the Initializer that generates tensors initialized to 0 for the intercept term\n",
    "\n",
    "- Creation of `self.b` variable via the `tf.Variable` class and initialized value, with `trainable=True`\n",
    "\n",
    "- Within the call function, `tf.matmul()` allows the Multiplication of matrix a by matrix b, producing a * b (in this case multiplies w.x) for the linear definition\n",
    "\n",
    "When we look at the line `Linear(units=4, input_dim=2)` that creates a linear  layer having the shape (4,2) and ready to use by calling it on some tensor input(s), much like a Python function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IAtBj2cRs6RZ"
   },
   "source": [
    "# Exercise 3 (CORE)\n",
    "\n",
    "For your created tensors above, \n",
    "\n",
    "- Build a linear regression model in keras. The model should consist of an input layer and a fully-connected output layer. See lecture notes for details of how to create these objects, previous WS materials or ask your tutors.\n",
    "\n",
    "- Compile the model. At this stage you need to select a loss function (specified via the \"loss\" keyword) and an optimizer. \n",
    "\n",
    "- Train the model with model.fit. Pass the keyword argument (similar to previous labs). Consider small number of `epochs` like 50 for the computational time reasons \n",
    "\n",
    "```\n",
    "# callbacks=[tensorboard_callback]\n",
    "```\n",
    "\n",
    "- You might also want to split the dataset into a training and validation component via  \n",
    "\n",
    "\n",
    "```\n",
    "# validation_split=0.3\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "NQdCePvVZqkE"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_layer = keras.layers.Input(shape=(1,))\n",
    "linear_layer = keras.layers.Dense(1, activation='linear')\n",
    "\n",
    "output = linear_layer(input_layer)\n",
    "model_lr = keras.models.Model(input_layer, output)\n",
    "model_lr.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 7796.7383 - val_loss: 8611.3018\n",
      "Epoch 2/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 7552.1411 - val_loss: 8298.6992\n",
      "Epoch 3/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 7313.2012 - val_loss: 8034.9360\n",
      "Epoch 4/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 7080.9868 - val_loss: 7686.1934\n",
      "Epoch 5/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 6855.9727 - val_loss: 7511.8638\n",
      "Epoch 6/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 6637.5112 - val_loss: 7208.0542\n",
      "Epoch 7/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 6424.9170 - val_loss: 6961.9761\n",
      "Epoch 8/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 6219.8628 - val_loss: 6680.5762\n",
      "Epoch 9/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 6020.6143 - val_loss: 6390.1504\n",
      "Epoch 10/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 5827.7007 - val_loss: 6146.1758\n",
      "Epoch 11/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 5641.1133 - val_loss: 5846.1816\n",
      "Epoch 12/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 5460.6328 - val_loss: 5664.4067\n",
      "Epoch 13/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 5287.7441 - val_loss: 5428.4375\n",
      "Epoch 14/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 5121.2090 - val_loss: 5271.4717\n",
      "Epoch 15/50\n",
      "2612/2612 [==============================] - 4s 1ms/step - loss: 4960.2075 - val_loss: 5015.8867\n",
      "Epoch 16/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 4806.4863 - val_loss: 4812.0327\n",
      "Epoch 17/50\n",
      "2612/2612 [==============================] - 5s 2ms/step - loss: 4659.7773 - val_loss: 4610.1260\n",
      "Epoch 18/50\n",
      "2612/2612 [==============================] - 5s 2ms/step - loss: 4518.1821 - val_loss: 4415.6299\n",
      "Epoch 19/50\n",
      "2612/2612 [==============================] - 5s 2ms/step - loss: 4383.8208 - val_loss: 4228.0532\n",
      "Epoch 20/50\n",
      "2612/2612 [==============================] - 5s 2ms/step - loss: 4255.8486 - val_loss: 4094.6309\n",
      "Epoch 21/50\n",
      "2612/2612 [==============================] - 5s 2ms/step - loss: 4133.4800 - val_loss: 3892.8013\n",
      "Epoch 22/50\n",
      "2612/2612 [==============================] - 5s 2ms/step - loss: 4018.3777 - val_loss: 3741.8623\n",
      "Epoch 23/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 3909.7573 - val_loss: 3589.2983\n",
      "Epoch 24/50\n",
      "2612/2612 [==============================] - 5s 2ms/step - loss: 3807.3999 - val_loss: 3447.4080\n",
      "Epoch 25/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 3710.1636 - val_loss: 3264.2952\n",
      "Epoch 26/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 3620.0508 - val_loss: 3178.4941\n",
      "Epoch 27/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 3536.2280 - val_loss: 3022.4885\n",
      "Epoch 28/50\n",
      "2612/2612 [==============================] - 4s 1ms/step - loss: 3457.9287 - val_loss: 2921.1584\n",
      "Epoch 29/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 3387.1855 - val_loss: 2801.5962\n",
      "Epoch 30/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 3321.0459 - val_loss: 2740.2607\n",
      "Epoch 31/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 3260.8621 - val_loss: 2649.2810\n",
      "Epoch 32/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 3206.6821 - val_loss: 2530.9675\n",
      "Epoch 33/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 3157.2136 - val_loss: 2412.5261\n",
      "Epoch 34/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 3114.0269 - val_loss: 2368.7502\n",
      "Epoch 35/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 3076.2822 - val_loss: 2302.4277\n",
      "Epoch 36/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 3042.7170 - val_loss: 2209.8779\n",
      "Epoch 37/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 3013.4277 - val_loss: 2179.4263\n",
      "Epoch 38/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 2989.0522 - val_loss: 2135.1609\n",
      "Epoch 39/50\n",
      "2612/2612 [==============================] - 4s 1ms/step - loss: 2968.4246 - val_loss: 2108.0027\n",
      "Epoch 40/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 2951.1699 - val_loss: 2045.2322\n",
      "Epoch 41/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 2937.2458 - val_loss: 2028.4211\n",
      "Epoch 42/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 2925.8245 - val_loss: 1991.2826\n",
      "Epoch 43/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 2916.4976 - val_loss: 1954.1440\n",
      "Epoch 44/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 2909.0276 - val_loss: 1937.7578\n",
      "Epoch 45/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 2903.2217 - val_loss: 1921.8351\n",
      "Epoch 46/50\n",
      "2612/2612 [==============================] - 6s 2ms/step - loss: 2898.5454 - val_loss: 1883.8143\n",
      "Epoch 47/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 2895.0229 - val_loss: 1889.1696\n",
      "Epoch 48/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 2892.4507 - val_loss: 1886.8225\n",
      "Epoch 49/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 2890.3772 - val_loss: 1864.9069\n",
      "Epoch 50/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 2888.9204 - val_loss: 1848.4983\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa1b05b85e0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lr.fit(x=X, y=y, epochs = 50, callbacks=[tensorboard_callback], \n",
    "             shuffle=True, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VgyMFi6K1gFE"
   },
   "source": [
    "# Exercise 4 (CORE)\n",
    "\n",
    "- Now create a new model with single feature by adding a fully-connected hidden layer with 2 neurons between your input and output above. Using the `linear` type of layers again.\n",
    "\n",
    "- Train the new model and comment on your fitted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "MFj2q0lj1quC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 2         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4\n",
      "Trainable params: 4\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_layer_an1 = keras.layers.Input(shape=(1,))\n",
    "hidden_layer_an1 = keras.layers.Dense(1, activation='linear')\n",
    "linear_layer_an1 = keras.layers.Dense(1, activation='linear')\n",
    "\n",
    "output_an1 = linear_layer_an1(hidden_layer_an1(input_layer_an1))\n",
    "model_an1 = keras.models.Model(input_layer_an1, output_an1)\n",
    "model_an1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2612/2612 [==============================] - 5s 2ms/step - loss: 68463.5469 - val_loss: 18012.5645\n",
      "Epoch 2/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 13265.2295 - val_loss: 13129.0312\n",
      "Epoch 3/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 8897.7334 - val_loss: 8184.1904\n",
      "Epoch 4/50\n",
      "2612/2612 [==============================] - 5s 2ms/step - loss: 7155.5430 - val_loss: 7739.2007\n",
      "Epoch 5/50\n",
      "2612/2612 [==============================] - 5s 2ms/step - loss: 6764.2354 - val_loss: 7177.9023\n",
      "Epoch 6/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 6188.4790 - val_loss: 6229.8047\n",
      "Epoch 7/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 5125.8330 - val_loss: 4299.8550\n",
      "Epoch 8/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 3738.3362 - val_loss: 2561.5623\n",
      "Epoch 9/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 2989.0278 - val_loss: 1903.9467\n",
      "Epoch 10/50\n",
      "2612/2612 [==============================] - 5s 2ms/step - loss: 2888.3682 - val_loss: 1782.9164\n",
      "Epoch 11/50\n",
      "2612/2612 [==============================] - 5s 2ms/step - loss: 2885.7290 - val_loss: 1761.8774\n",
      "Epoch 12/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 2885.9517 - val_loss: 1817.5946\n",
      "Epoch 13/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 2886.2686 - val_loss: 1841.2717\n",
      "Epoch 14/50\n",
      "2612/2612 [==============================] - 5s 2ms/step - loss: 2886.1052 - val_loss: 1835.1880\n",
      "Epoch 15/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 2886.6418 - val_loss: 1839.9867\n",
      "Epoch 16/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 2885.4941 - val_loss: 1802.9561\n",
      "Epoch 17/50\n",
      "2612/2612 [==============================] - 5s 2ms/step - loss: 2886.1621 - val_loss: 1764.0439\n",
      "Epoch 18/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 2886.3091 - val_loss: 1829.7522\n",
      "Epoch 19/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 2886.1707 - val_loss: 1834.3475\n",
      "Epoch 20/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 2885.9497 - val_loss: 1818.4768\n",
      "Epoch 21/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 2886.7874 - val_loss: 1804.2585\n",
      "Epoch 22/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 2886.4272 - val_loss: 1836.5507\n",
      "Epoch 23/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 2886.4663 - val_loss: 1774.5022\n",
      "Epoch 24/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 2886.9106 - val_loss: 1764.5194\n",
      "Epoch 25/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 2885.6094 - val_loss: 1747.9164\n",
      "Epoch 26/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 2886.8264 - val_loss: 1794.8372\n",
      "Epoch 27/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 2886.0442 - val_loss: 1806.0592\n",
      "Epoch 28/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 2886.0972 - val_loss: 1763.1519\n",
      "Epoch 29/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 2886.3008 - val_loss: 1821.6368\n",
      "Epoch 30/50\n",
      "2612/2612 [==============================] - 5s 2ms/step - loss: 2886.3391 - val_loss: 1856.6113\n",
      "Epoch 31/50\n",
      "2612/2612 [==============================] - 5s 2ms/step - loss: 2886.2998 - val_loss: 1812.3553\n",
      "Epoch 32/50\n",
      "2612/2612 [==============================] - 5s 2ms/step - loss: 2885.8054 - val_loss: 1790.6060\n",
      "Epoch 33/50\n",
      "2612/2612 [==============================] - 6s 2ms/step - loss: 2886.2131 - val_loss: 1812.2214\n",
      "Epoch 34/50\n",
      "2612/2612 [==============================] - 5s 2ms/step - loss: 2886.7012 - val_loss: 1771.3167\n",
      "Epoch 35/50\n",
      "2612/2612 [==============================] - 5s 2ms/step - loss: 2885.3452 - val_loss: 1785.8163\n",
      "Epoch 36/50\n",
      "2612/2612 [==============================] - 5s 2ms/step - loss: 2885.8870 - val_loss: 1797.5797\n",
      "Epoch 37/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 2885.6455 - val_loss: 1835.3522\n",
      "Epoch 38/50\n",
      "2612/2612 [==============================] - 5s 2ms/step - loss: 2886.3616 - val_loss: 1816.7045\n",
      "Epoch 39/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 2886.4243 - val_loss: 1804.8243\n",
      "Epoch 40/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 2886.2673 - val_loss: 1764.5430\n",
      "Epoch 41/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 2886.0786 - val_loss: 1806.6161\n",
      "Epoch 42/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 2886.3296 - val_loss: 1756.9821\n",
      "Epoch 43/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 2885.8015 - val_loss: 1791.6063\n",
      "Epoch 44/50\n",
      "2612/2612 [==============================] - 5s 2ms/step - loss: 2886.0332 - val_loss: 1806.8521\n",
      "Epoch 45/50\n",
      "2612/2612 [==============================] - 5s 2ms/step - loss: 2885.8550 - val_loss: 1794.9860\n",
      "Epoch 46/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 2885.8267 - val_loss: 1803.4152\n",
      "Epoch 47/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 2886.0117 - val_loss: 1775.2169\n",
      "Epoch 48/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 2886.3074 - val_loss: 1771.6580\n",
      "Epoch 49/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 2886.0244 - val_loss: 1801.2821\n",
      "Epoch 50/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 2886.0146 - val_loss: 1822.9551\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa1b029dca0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_an1.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "model_an1.fit(x=X, y=y, epochs = 50, callbacks=[tensorboard_callback], \n",
    "             shuffle=True, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_qcl7L-v812b"
   },
   "source": [
    "# Exercise 5 (CORE)\n",
    "\n",
    "To run the single-variable linear regression using keras, we can benefit from `Sequential` model idea as well\n",
    "\n",
    "- See the details of added normalization layer below\n",
    "\n",
    "- Compile the created model below and try to produce the model's training progress using the stats stored in the history object:\n",
    "\n",
    "For more details, see example given here : https://www.tensorflow.org/tutorials/keras/regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Variable selection\n",
    "lead_time = np.array(df_hotel['lead_time'])\n",
    "\n",
    "# About normalization by keras\n",
    "lead_time_normalizer = layers.Normalization(input_shape=[1,], axis=None)\n",
    "lead_time_normalizer.adapt(lead_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "prELosLWIwHt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization (Normalizatio  (None, 1)                3         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5\n",
      "Trainable params: 2\n",
      "Non-trainable params: 3\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Created model including normalization\n",
    "linear_model = tf.keras.Sequential([\n",
    "    lead_time_normalizer,\n",
    "    layers.Dense(units=1, activation='linear')\n",
    "])\n",
    "\n",
    "linear_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model \n",
    "linear_model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(),\n",
    "    loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2612/2612 [==============================] - 5s 2ms/step - loss: 12163.0410 - val_loss: 13587.5117\n",
      "Epoch 2/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 11671.9609 - val_loss: 13045.4795\n",
      "Epoch 3/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 11195.7793 - val_loss: 12512.1982\n",
      "Epoch 4/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 10734.0684 - val_loss: 11991.1035\n",
      "Epoch 5/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 10285.9238 - val_loss: 11479.7686\n",
      "Epoch 6/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 9851.6719 - val_loss: 10981.2031\n",
      "Epoch 7/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 9431.3389 - val_loss: 10493.5498\n",
      "Epoch 8/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 9024.3730 - val_loss: 10018.2656\n",
      "Epoch 9/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 8630.6094 - val_loss: 9555.3535\n",
      "Epoch 10/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 8250.0732 - val_loss: 9104.3984\n",
      "Epoch 11/50\n",
      "2612/2612 [==============================] - 5s 2ms/step - loss: 7883.0674 - val_loss: 8667.1250\n",
      "Epoch 12/50\n",
      "2612/2612 [==============================] - 4s 1ms/step - loss: 7529.4927 - val_loss: 8242.7764\n",
      "Epoch 13/50\n",
      "2612/2612 [==============================] - 4s 1ms/step - loss: 7189.3794 - val_loss: 7831.1147\n",
      "Epoch 14/50\n",
      "2612/2612 [==============================] - 4s 1ms/step - loss: 6862.7554 - val_loss: 7433.2832\n",
      "Epoch 15/50\n",
      "2612/2612 [==============================] - 4s 1ms/step - loss: 6549.4287 - val_loss: 7048.9629\n",
      "Epoch 16/50\n",
      "2612/2612 [==============================] - 4s 1ms/step - loss: 6249.1855 - val_loss: 6677.7891\n",
      "Epoch 17/50\n",
      "2612/2612 [==============================] - 4s 1ms/step - loss: 5962.8091 - val_loss: 6320.5723\n",
      "Epoch 18/50\n",
      "2612/2612 [==============================] - 4s 1ms/step - loss: 5688.7891 - val_loss: 5975.8154\n",
      "Epoch 19/50\n",
      "2612/2612 [==============================] - 4s 1ms/step - loss: 5428.3823 - val_loss: 5645.9927\n",
      "Epoch 20/50\n",
      "2612/2612 [==============================] - 4s 1ms/step - loss: 5181.5537 - val_loss: 5329.3398\n",
      "Epoch 21/50\n",
      "2612/2612 [==============================] - 4s 1ms/step - loss: 4948.4150 - val_loss: 5027.8340\n",
      "Epoch 22/50\n",
      "2612/2612 [==============================] - 4s 1ms/step - loss: 4728.0703 - val_loss: 4738.7002\n",
      "Epoch 23/50\n",
      "2612/2612 [==============================] - 3s 1ms/step - loss: 4520.1377 - val_loss: 4463.4570\n",
      "Epoch 24/50\n",
      "2612/2612 [==============================] - 4s 1ms/step - loss: 4326.1699 - val_loss: 4203.1704\n",
      "Epoch 25/50\n",
      "2612/2612 [==============================] - 4s 1ms/step - loss: 4145.3857 - val_loss: 3956.0862\n",
      "Epoch 26/50\n",
      "2612/2612 [==============================] - 3s 1ms/step - loss: 3977.5381 - val_loss: 3722.8096\n",
      "Epoch 27/50\n",
      "2612/2612 [==============================] - 4s 1ms/step - loss: 3822.6023 - val_loss: 3503.4006\n",
      "Epoch 28/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 3680.2910 - val_loss: 3297.5452\n",
      "Epoch 29/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 3551.4248 - val_loss: 3107.4849\n",
      "Epoch 30/50\n",
      "2612/2612 [==============================] - 5s 2ms/step - loss: 3436.1091 - val_loss: 2931.3599\n",
      "Epoch 31/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 3332.6121 - val_loss: 2767.9478\n",
      "Epoch 32/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 3241.2781 - val_loss: 2619.1760\n",
      "Epoch 33/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 3162.8481 - val_loss: 2485.0181\n",
      "Epoch 34/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 3095.7480 - val_loss: 2365.2463\n",
      "Epoch 35/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 3040.4280 - val_loss: 2259.0437\n",
      "Epoch 36/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 2995.5005 - val_loss: 2166.6609\n",
      "Epoch 37/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 2960.9783 - val_loss: 2090.9294\n",
      "Epoch 38/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 2935.4739 - val_loss: 2026.7412\n",
      "Epoch 39/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 2916.5076 - val_loss: 1973.8002\n",
      "Epoch 40/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 2903.9963 - val_loss: 1933.8942\n",
      "Epoch 41/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 2895.9565 - val_loss: 1903.2592\n",
      "Epoch 42/50\n",
      "2612/2612 [==============================] - 5s 2ms/step - loss: 2890.8250 - val_loss: 1879.6382\n",
      "Epoch 43/50\n",
      "2612/2612 [==============================] - 5s 2ms/step - loss: 2887.6250 - val_loss: 1861.2705\n",
      "Epoch 44/50\n",
      "2612/2612 [==============================] - 5s 2ms/step - loss: 2885.7581 - val_loss: 1848.3607\n",
      "Epoch 45/50\n",
      "2612/2612 [==============================] - 5s 2ms/step - loss: 2884.6338 - val_loss: 1838.1986\n",
      "Epoch 46/50\n",
      "2612/2612 [==============================] - 5s 2ms/step - loss: 2883.9565 - val_loss: 1830.6708\n",
      "Epoch 47/50\n",
      "2612/2612 [==============================] - 5s 2ms/step - loss: 2883.5583 - val_loss: 1824.8059\n",
      "Epoch 48/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 2883.3228 - val_loss: 1820.3809\n",
      "Epoch 49/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 2883.1948 - val_loss: 1817.3912\n",
      "Epoch 50/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 2883.1160 - val_loss: 1814.7714\n"
     ]
    }
   ],
   "source": [
    "# Use Keras Model.fit to execute the training for 50 epochs:\n",
    "# %%time\n",
    "history = linear_model.fit(\n",
    "    df_hotel['lead_time'], df_hotel['adr'],\n",
    "    epochs = 50,\n",
    "    # Calculate validation results on 30% of the training data.\n",
    "    validation_split = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2883.956543</td>\n",
       "      <td>1830.670776</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2883.558350</td>\n",
       "      <td>1824.805908</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2883.322754</td>\n",
       "      <td>1820.380859</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2883.194824</td>\n",
       "      <td>1817.391235</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2883.115967</td>\n",
       "      <td>1814.771362</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           loss     val_loss  epoch\n",
       "45  2883.956543  1830.670776     45\n",
       "46  2883.558350  1824.805908     46\n",
       "47  2883.322754  1820.380859     47\n",
       "48  2883.194824  1817.391235     48\n",
       "49  2883.115967  1814.771362     49"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize the model's training progress using the stats stored in the history object:\n",
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the behaviour of training and validation loss functions\n",
    "# Consider the below function simply \n",
    "\n",
    "def plot_loss(history):\n",
    "  plt.plot(history.history['loss'], label='loss')\n",
    "  plt.plot(history.history['val_loss'], label='val_loss')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Error')\n",
    "  plt.legend()\n",
    "  plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6 (CORE)\n",
    "\n",
    "Consider your hotel data once again. Officially, our response is binary and supposed to be the `is_canceled` in the data set. So, we are interested in predicting a binary response here so the problem is classification. \n",
    "\n",
    "- Consider fitting a logistic regression model in keras similar to Exercise 3. The model should consist of an input layer and a fully-connected output layer. Choose one single numerical predictor, such as `lead_time` to do this experiment\n",
    "\n",
    "- Which activation function you used and how is the progress of the model fit with `epochs = 50` and `validation_split=0.3` (You can benefit from the plotting introduced before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the response with a single predictor\n",
    "X = df_hotel['lead_time']\n",
    "y = df_hotel['is_canceled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_layer = keras.layers.Input(shape=(1,))\n",
    "logit_layer = keras.layers.Dense(1, activation='sigmoid')\n",
    "\n",
    "output = logit_layer(input_layer)\n",
    "model_lr = keras.models.Model(input_layer, output)\n",
    "model_lr.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2612/2612 [==============================] - 5s 2ms/step - loss: 1.8561 - val_loss: 0.8174\n",
      "Epoch 2/50\n",
      "2612/2612 [==============================] - 5s 2ms/step - loss: 0.6400 - val_loss: 0.6390\n",
      "Epoch 3/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 0.6402 - val_loss: 0.8977\n",
      "Epoch 4/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 0.6404 - val_loss: 0.6469\n",
      "Epoch 5/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 0.6407 - val_loss: 0.8120\n",
      "Epoch 6/50\n",
      "2612/2612 [==============================] - 5s 2ms/step - loss: 0.6406 - val_loss: 0.8106\n",
      "Epoch 7/50\n",
      "2612/2612 [==============================] - 5s 2ms/step - loss: 0.6405 - val_loss: 0.8117\n",
      "Epoch 8/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 0.6404 - val_loss: 0.7642\n",
      "Epoch 9/50\n",
      "2612/2612 [==============================] - 5s 2ms/step - loss: 0.6401 - val_loss: 0.7518\n",
      "Epoch 10/50\n",
      "2612/2612 [==============================] - 5s 2ms/step - loss: 0.6405 - val_loss: 0.7103\n",
      "Epoch 11/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 0.6403 - val_loss: 0.8027\n",
      "Epoch 12/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 0.6404 - val_loss: 0.6519\n",
      "Epoch 13/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 0.6402 - val_loss: 0.7652\n",
      "Epoch 14/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 0.6409 - val_loss: 0.8274\n",
      "Epoch 15/50\n",
      "2612/2612 [==============================] - 5s 2ms/step - loss: 0.6407 - val_loss: 0.8899\n",
      "Epoch 16/50\n",
      "2612/2612 [==============================] - 5s 2ms/step - loss: 0.6403 - val_loss: 0.6516\n",
      "Epoch 17/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 0.6402 - val_loss: 0.7731\n",
      "Epoch 18/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 0.6404 - val_loss: 0.8094\n",
      "Epoch 19/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 0.6401 - val_loss: 0.6696\n",
      "Epoch 20/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 0.6401 - val_loss: 0.7107\n",
      "Epoch 21/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 0.6404 - val_loss: 0.7219\n",
      "Epoch 22/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 0.6403 - val_loss: 0.7748\n",
      "Epoch 23/50\n",
      "2612/2612 [==============================] - 5s 2ms/step - loss: 0.6403 - val_loss: 0.6889\n",
      "Epoch 24/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 0.6404 - val_loss: 0.7602\n",
      "Epoch 25/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 0.6402 - val_loss: 0.7031\n",
      "Epoch 26/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 0.6403 - val_loss: 0.6629\n",
      "Epoch 27/50\n",
      "2612/2612 [==============================] - 5s 2ms/step - loss: 0.6403 - val_loss: 0.8152\n",
      "Epoch 28/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 0.6404 - val_loss: 0.6433\n",
      "Epoch 29/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 0.6406 - val_loss: 0.7673\n",
      "Epoch 30/50\n",
      "2612/2612 [==============================] - 5s 2ms/step - loss: 0.6404 - val_loss: 0.6450\n",
      "Epoch 31/50\n",
      "2612/2612 [==============================] - 5s 2ms/step - loss: 0.6402 - val_loss: 0.7635\n",
      "Epoch 32/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 0.6408 - val_loss: 0.7467\n",
      "Epoch 33/50\n",
      "2612/2612 [==============================] - 5s 2ms/step - loss: 0.6406 - val_loss: 0.7341\n",
      "Epoch 34/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 0.6401 - val_loss: 0.8052\n",
      "Epoch 35/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 0.6401 - val_loss: 0.7644\n",
      "Epoch 36/50\n",
      "2612/2612 [==============================] - 5s 2ms/step - loss: 0.6404 - val_loss: 0.8042\n",
      "Epoch 37/50\n",
      "2612/2612 [==============================] - 5s 2ms/step - loss: 0.6403 - val_loss: 0.6799\n",
      "Epoch 38/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 0.6401 - val_loss: 0.8050\n",
      "Epoch 39/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 0.6409 - val_loss: 0.6738\n",
      "Epoch 40/50\n",
      "2612/2612 [==============================] - 5s 2ms/step - loss: 0.6398 - val_loss: 0.7329\n",
      "Epoch 41/50\n",
      "2612/2612 [==============================] - 5s 2ms/step - loss: 0.6404 - val_loss: 0.6675\n",
      "Epoch 42/50\n",
      "2612/2612 [==============================] - 5s 2ms/step - loss: 0.6401 - val_loss: 0.9450\n",
      "Epoch 43/50\n",
      "2612/2612 [==============================] - 5s 2ms/step - loss: 0.6409 - val_loss: 0.6996\n",
      "Epoch 44/50\n",
      "2612/2612 [==============================] - 5s 2ms/step - loss: 0.6408 - val_loss: 0.6724\n",
      "Epoch 45/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 0.6403 - val_loss: 0.8799\n",
      "Epoch 46/50\n",
      "2612/2612 [==============================] - 5s 2ms/step - loss: 0.6408 - val_loss: 0.7907\n",
      "Epoch 47/50\n",
      "2612/2612 [==============================] - 5s 2ms/step - loss: 0.6403 - val_loss: 0.6705\n",
      "Epoch 48/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 0.6400 - val_loss: 0.6754\n",
      "Epoch 49/50\n",
      "2612/2612 [==============================] - 4s 2ms/step - loss: 0.6404 - val_loss: 0.8018\n",
      "Epoch 50/50\n",
      "2612/2612 [==============================] - 5s 2ms/step - loss: 0.6402 - val_loss: 0.7866\n"
     ]
    }
   ],
   "source": [
    "history = model_lr.fit(x = X, y = y, epochs = 50, \n",
    "                       callbacks = [tensorboard_callback], shuffle = True, validation_split = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the model's training progress using the stats stored in the history object:\n",
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "\n",
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3731/3731 [==============================] - 3s 908us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.8873185 , 0.99416655, 0.36726087, ..., 0.4173117 , 0.562171  ,\n",
       "       0.730515  ], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# About Predictions\n",
    "y_pred = model_lr.predict(X).flatten()\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7 (CORE)\n",
    "\n",
    "- Calculate your model predictions on the original data set (using the 0.5 threshold for the decision boundary)\n",
    "\n",
    "- Compare your findings with your ground truth (true observations for `is_canceled` variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119390, 1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Class labels\n",
    "y_pred_lab = np.zeros((y.shape[0], 1))\n",
    "y_pred_lab.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 0. ... 0. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "y_pred_lab = y_pred\n",
    "\n",
    "y_pred_lab[y_pred_lab > 0.5] = 1\n",
    "y_pred_lab[y_pred_lab <= 0.5] = 0\n",
    "print(y_pred_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[46674, 28492],\n",
       "       [16260, 27964]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To compare with the true observations\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#using the confusion matrix, but not strictly necessary for this task\n",
    "confmat = confusion_matrix(y_true = y, y_pred = y_pred_lab)\n",
    "confmat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 8 (EXTRA)\n",
    "\n",
    "For the hotel data set, as an extension of above mentioned method;\n",
    "\n",
    "1. Lets create our feature matrix (including some variables) and response varible (`is_canceled`). You can think of set of predictors (suitable and ready to use predictors)\n",
    "\n",
    "2.  Split the data into training and test sets as usual. Use the test size as $30\\%$ of the whole sample herein.\n",
    "\n",
    "3. Re-create the above logistic model (the model should consist of an input layer and a fully-connected output layer) and train the model using only training data now (Remember that validation over the training set still makes sense!)\n",
    "\n",
    "4. Derive the predictions of the fitted model over the test data (unseen data set by the NN model)\n",
    "\n",
    "**WARNING :** Note that, these steps are followed under the assumption that all the necessary data cleaning was completed generally.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the simplicity look at two variables to illustrate \n",
    "\n",
    "# Define the response with a single predictor\n",
    "X = df_hotel[['lead_time', 'adr']]\n",
    "y = df_hotel['is_canceled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((83573, 2), (35817, 2), (83573,), (35817,))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, \n",
    "                                                    test_size = 0.3, random_state=42)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 2)]               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3\n",
      "Trainable params: 3\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_layer = keras.layers.Input(shape=(2,))\n",
    "logit_layer = keras.layers.Dense(1, activation='sigmoid')\n",
    "\n",
    "output = logit_layer(input_layer)\n",
    "model_lr = keras.models.Model(input_layer, output)\n",
    "model_lr.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 10.6556 - val_loss: 0.6351\n",
      "Epoch 2/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6306 - val_loss: 0.6298\n",
      "Epoch 3/50\n",
      "1829/1829 [==============================] - 3s 1ms/step - loss: 0.6235 - val_loss: 0.6166\n",
      "Epoch 4/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6200 - val_loss: 0.6133\n",
      "Epoch 5/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6192 - val_loss: 0.6140\n",
      "Epoch 6/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6199 - val_loss: 0.6133\n",
      "Epoch 7/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6200 - val_loss: 0.6166\n",
      "Epoch 8/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6185 - val_loss: 0.6141\n",
      "Epoch 9/50\n",
      "1829/1829 [==============================] - 3s 1ms/step - loss: 0.6189 - val_loss: 0.6163\n",
      "Epoch 10/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6186 - val_loss: 0.6162\n",
      "Epoch 11/50\n",
      "1829/1829 [==============================] - 3s 1ms/step - loss: 0.6192 - val_loss: 0.6145\n",
      "Epoch 12/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6192 - val_loss: 0.6140\n",
      "Epoch 13/50\n",
      "1829/1829 [==============================] - 3s 1ms/step - loss: 0.6191 - val_loss: 0.6172\n",
      "Epoch 14/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6188 - val_loss: 0.6140\n",
      "Epoch 15/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6186 - val_loss: 0.6146\n",
      "Epoch 16/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6185 - val_loss: 0.6133\n",
      "Epoch 17/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6190 - val_loss: 0.6173\n",
      "Epoch 18/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6190 - val_loss: 0.6206\n",
      "Epoch 19/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6191 - val_loss: 0.6216\n",
      "Epoch 20/50\n",
      "1829/1829 [==============================] - 3s 1ms/step - loss: 0.6186 - val_loss: 0.6182\n",
      "Epoch 21/50\n",
      "1829/1829 [==============================] - 3s 1ms/step - loss: 0.6186 - val_loss: 0.6134\n",
      "Epoch 22/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6191 - val_loss: 0.6158\n",
      "Epoch 23/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6192 - val_loss: 0.6138\n",
      "Epoch 24/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6189 - val_loss: 0.6196\n",
      "Epoch 25/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6187 - val_loss: 0.6399\n",
      "Epoch 26/50\n",
      "1829/1829 [==============================] - 3s 1ms/step - loss: 0.6189 - val_loss: 0.6219\n",
      "Epoch 27/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6193 - val_loss: 0.6161\n",
      "Epoch 28/50\n",
      "1829/1829 [==============================] - 3s 1ms/step - loss: 0.6181 - val_loss: 0.6198\n",
      "Epoch 29/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6186 - val_loss: 0.6183\n",
      "Epoch 30/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6185 - val_loss: 0.6177\n",
      "Epoch 31/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6189 - val_loss: 0.6152\n",
      "Epoch 32/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6188 - val_loss: 0.6189\n",
      "Epoch 33/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6193 - val_loss: 0.6242\n",
      "Epoch 34/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6189 - val_loss: 0.6168\n",
      "Epoch 35/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6192 - val_loss: 0.6140\n",
      "Epoch 36/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6181 - val_loss: 0.6187\n",
      "Epoch 37/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6193 - val_loss: 0.6164\n",
      "Epoch 38/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6190 - val_loss: 0.6138\n",
      "Epoch 39/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6196 - val_loss: 0.6156\n",
      "Epoch 40/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6187 - val_loss: 0.6228\n",
      "Epoch 41/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6194 - val_loss: 0.6222\n",
      "Epoch 42/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6191 - val_loss: 0.6220\n",
      "Epoch 43/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6186 - val_loss: 0.6128\n",
      "Epoch 44/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6189 - val_loss: 0.6189\n",
      "Epoch 45/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6187 - val_loss: 0.6159\n",
      "Epoch 46/50\n",
      "1829/1829 [==============================] - 3s 1ms/step - loss: 0.6188 - val_loss: 0.6156\n",
      "Epoch 47/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6188 - val_loss: 0.6273\n",
      "Epoch 48/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6181 - val_loss: 0.6218\n",
      "Epoch 49/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6192 - val_loss: 0.6147\n",
      "Epoch 50/50\n",
      "1829/1829 [==============================] - 3s 1ms/step - loss: 0.6184 - val_loss: 0.6169\n"
     ]
    }
   ],
   "source": [
    "history = model_lr.fit(x = X_train, y = y_train, epochs = 50, \n",
    "                       callbacks = [tensorboard_callback], shuffle = True, validation_split = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1120/1120 [==============================] - 1s 833us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.23743105, 0.39793158, 0.6115089 , ..., 0.28781748, 0.3750703 ,\n",
       "       0.21398857], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# About Predictions\n",
    "y_pred_test = model_lr.predict(X_test).flatten()\n",
    "y_pred_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Class labels\n",
    "y_pred_lab = np.zeros((y_test.shape[0], 1))\n",
    "y_pred_lab.shape\n",
    "\n",
    "y_pred_lab = y_pred_test\n",
    "\n",
    "y_pred_lab[y_pred_lab > 0.5] = 1\n",
    "y_pred_lab[y_pred_lab <= 0.5] = 0\n",
    "print(y_pred_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[20974,  1576],\n",
       "       [10543,  2724]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To compare with the true observations\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#using the confusion matrix, but not strictly necessary for this task\n",
    "confmat = confusion_matrix(y_true = y_test, y_pred = y_pred_lab)\n",
    "confmat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1CvMFdEvvXtt"
   },
   "source": [
    "# Exercise 9 (EXTRA)\n",
    "\n",
    "By changing the NN model a bit further;\n",
    "\n",
    "1. Create a new model by adding a fully-connected hidden layer with 2 neurons between your input and output above.\n",
    "\n",
    "2. Play around the considered activation functions (adding `relu` etc. instead of logistic)\n",
    "\n",
    "3. Train the new model over the training data and consider your predictions over the test data again. Compare your predictions with the true test values\n",
    "\n",
    "4. Visualize the model's training progress similar to the previous graphical outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 2)]               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 3         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5\n",
      "Trainable params: 5\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Just for an illustration \n",
    "\n",
    "input_layer_an2 = keras.layers.Input(shape=(2,))\n",
    "hidden_layer_an2 = keras.layers.Dense(1, activation='relu')\n",
    "logit_layer_an2 = keras.layers.Dense(1, activation='relu')\n",
    "\n",
    "output_an2 = logit_layer_an2(hidden_layer_an2(input_layer_an2))\n",
    "model_an2 = keras.models.Model(input_layer_an2, output_an2)\n",
    "model_an2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 4.9958 - val_loss: 4.3535\n",
      "Epoch 2/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 4.0974 - val_loss: 3.7188\n",
      "Epoch 3/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 3.5661 - val_loss: 3.3350\n",
      "Epoch 4/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 2.9258 - val_loss: 2.7894\n",
      "Epoch 5/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 2.8486 - val_loss: 2.7608\n",
      "Epoch 6/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 2.8194 - val_loss: 2.7295\n",
      "Epoch 7/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 2.7713 - val_loss: 2.6109\n",
      "Epoch 8/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 2.5838 - val_loss: 2.3755\n",
      "Epoch 9/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 2.2402 - val_loss: 1.8506\n",
      "Epoch 10/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 1.7679 - val_loss: 1.2660\n",
      "Epoch 11/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6726 - val_loss: 0.6400\n",
      "Epoch 12/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.8116 - val_loss: 0.6438\n",
      "Epoch 13/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6436 - val_loss: 0.6420\n",
      "Epoch 14/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6643 - val_loss: 0.6699\n",
      "Epoch 15/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6483 - val_loss: 0.6435\n",
      "Epoch 16/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6543 - val_loss: 0.6523\n",
      "Epoch 17/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6484 - val_loss: 0.6432\n",
      "Epoch 18/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6493 - val_loss: 0.6432\n",
      "Epoch 19/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6565 - val_loss: 0.6489\n",
      "Epoch 20/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6453 - val_loss: 0.6440\n",
      "Epoch 21/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.7037 - val_loss: 0.6623\n",
      "Epoch 22/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6601 - val_loss: 0.6599\n",
      "Epoch 23/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6589 - val_loss: 0.6603\n",
      "Epoch 24/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6589 - val_loss: 0.6599\n",
      "Epoch 25/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6594 - val_loss: 0.6599\n",
      "Epoch 26/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6589 - val_loss: 0.6599\n",
      "Epoch 27/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6589 - val_loss: 0.6598\n",
      "Epoch 28/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6593 - val_loss: 0.6600\n",
      "Epoch 29/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6589 - val_loss: 0.6600\n",
      "Epoch 30/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6589 - val_loss: 0.6600\n",
      "Epoch 31/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6590 - val_loss: 0.6601\n",
      "Epoch 32/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6589 - val_loss: 0.6600\n",
      "Epoch 33/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6589 - val_loss: 0.6601\n",
      "Epoch 34/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6590 - val_loss: 0.6600\n",
      "Epoch 35/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6589 - val_loss: 0.6600\n",
      "Epoch 36/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6603 - val_loss: 0.6653\n",
      "Epoch 37/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6596 - val_loss: 0.6600\n",
      "Epoch 38/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6589 - val_loss: 0.6599\n",
      "Epoch 39/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6596 - val_loss: 0.6602\n",
      "Epoch 40/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6590 - val_loss: 0.6601\n",
      "Epoch 41/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6590 - val_loss: 0.6601\n",
      "Epoch 42/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6589 - val_loss: 0.6603\n",
      "Epoch 43/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6588 - val_loss: 0.6601\n",
      "Epoch 44/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6589 - val_loss: 0.6600\n",
      "Epoch 45/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6590 - val_loss: 0.6601\n",
      "Epoch 46/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6610 - val_loss: 0.6683\n",
      "Epoch 47/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6669 - val_loss: 0.6616\n",
      "Epoch 48/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6611 - val_loss: 0.6601\n",
      "Epoch 49/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6589 - val_loss: 0.6600\n",
      "Epoch 50/50\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.6589 - val_loss: 0.6600\n"
     ]
    }
   ],
   "source": [
    "model_an2.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "history = model_an2.fit(x = X_train, y = y_train, epochs = 50, \n",
    "                       callbacks = [tensorboard_callback], shuffle = True, validation_split = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1120/1120 [==============================] - 1s 826us/step\n",
      "[0. 0. 1. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# About Predictions\n",
    "y_pred_test = model_lr.predict(X_test).flatten()\n",
    "y_pred_test\n",
    "\n",
    "\n",
    "# Class labels\n",
    "y_pred_lab = np.zeros((y_test.shape[0], 1))\n",
    "y_pred_lab.shape\n",
    "\n",
    "y_pred_lab = y_pred_test\n",
    "\n",
    "y_pred_lab[y_pred_lab > 0.5] = 1\n",
    "y_pred_lab[y_pred_lab <= 0.5] = 0\n",
    "print(y_pred_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[20974,  1576],\n",
       "       [10543,  2724]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To compare with the true observations\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#using the confusion matrix, but not strictly necessary for this task\n",
    "confmat = confusion_matrix(y_true = y_test, y_pred = y_pred_lab)\n",
    "confmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEGCAYAAABvtY4XAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAnlUlEQVR4nO3de3xU9Z3/8ddnJpP7hUAuQAKEcPPCVQKClZtri22t3drWota6vbnV1tr+qqvubrduL9vuum1/29ZHu7Z11aoFV+3WS2vrT6HIisr9JheRayBCAgTIPZn5/v44QwyQQBKYTObM+/l4jDNz5pw5n2+Ad75+z3e+Y845RETEfwLxLkBERGJDAS8i4lMKeBERn1LAi4j4lAJeRMSnUuJdQEcFBQWurKysV8fW19eTlZV1fgtKAGp3clG7k0t32r1q1aoa51xhZ6/1q4AvKytj5cqVvTp2yZIlzJ079/wWlADU7uSidieX7rTbzHZ39ZqGaEREfEoBLyLiUwp4ERGf6ldj8CKSfFpbW6msrKSpqanLffLy8ti8eXMfVtU/dGx3eno6paWlhEKhbh+vgBeRuKqsrCQnJ4eysjLMrNN9jh8/Tk5OTh9XFn8n2u2c49ChQ1RWVjJy5MhuHx/TgDezXcBxIAy0OecqYnk+EUk8TU1NZwx3ATNj0KBBVFdX9+i4vujBz3PO1fTBeUQkQSncz643P6OEv8jaFo7wwOLtbKxpi3cpIiL9isVyPXgz2wkcARzwn865BzvZ5xbgFoDi4uKpCxcu7NE5nHN85ZUGpgxyfGFy9nmoOrHU1dWRna12Jws/tjsvL4/Ro0efcZ9wOEwwGIxZDUOGDKGqqipm799bp7Z7+/btHD169KR95s2bt6qr4e9YD9G8zzm338yKgJfMbItzbmnHHaKh/yBARUWF682n1cZu/l8O1R3TJ92SiNrtH5s3bz7rBdS+uMjaHy/intru9PR0pkyZ0u3jYzpE45zbH70/CPwOmB6L85QXZFNVr2+mEpFz45zjrrvuYvz48UyYMIFFixYBUFVVxezZs5k8eTLjx4/n1VdfJRwO8zd/8zft+/74xz+Oc/Wni1kP3syygIBz7nj08QeAb8fiXOWFWTzd7KhrbiM7TTM/RRLVPz+3ibf2Hztt+7kM0Vw0NJdvfeTibu37zDPPsHbtWtatW0dNTQ3Tpk1j9uzZPPHEE8yfP59/+Id/IBwO09DQwNq1a9m3bx8bN24EoLa2tlf1xVIse/DFwDIzWwe8CbzgnHsxFicaVeittrazuj4Wby8iSWLZsmVcf/31BINBiouLmTNnDitWrGDatGn813/9F/fddx8bNmwgJyeH8vJyduzYwe23386LL75Ibm5uvMs/Tcy6u865HcCkWL1/R+WF3kWnHTV1TCjN64tTikgMdNXT7qsPOnU16WT27NksXbqUF154gZtuuom77rqLz3zmM6xbt44//elPPPDAAzz55JM89NBDMa+xJxJ+miTAiEGZGPCOevAicg5mz57NokWLCIfDVFdXs3TpUqZPn87u3bspKirii1/8Ip///OdZvXo1NTU1RCIRPv7xj/Od73yH1atXx7v80/hiwDotJUhBhrGjui7epYhIAvvYxz7G8uXLmTRpEmbGv/3bvzF48GAeeeQR7r//fkKhENnZ2Tz66KPs27ePz372s0QiEQC+//3vx7n60/ki4AGGZAXYoR68iPRCXZ3XOTQz7r//fu6///6TXr/55pu5+eabTzuuP/baO/LFEA3A4CxjZ009kYimS4qIgK8CPkBja5h3j3W95KiISDLxTcAPyfKaomEaERGPbwJ+cJa30tqOGl1oFREBHwX8gDQjKzWoHryISJRvAt7MKC/M5h1NlRQRAXwU8OCtSaMevIiIx18BX5DN/qONNLaE412KiPjUmdbj37VrF+PHj+/Das7MXwFfmIVzsLNGvXgREd98khW8gAdvJs1FQ/vfym4ichZ/vAfe3XDa5oxwGwR7GVeDJ8AHf9Dly3fffTcjRozgtttuA+C+++7DzFi6dClHjhyhtbWV7373u3z0ox/t0Wmbmpq49dZbWblyJSkpKfzoRz9i3rx5bNq0ic9+9rO0tLQQiUR4+umnGTp0KNdddx2VlZWEw2G++c1v8qlPfap37e3AVwE/siAa8BqHF5FuWrBgAV/72tfaA/7JJ5/kxRdf5Otf/zq5ubnU1NQwY8YMrrnmmh598fUDDzwAwIYNG9iyZQsf+MAH2LZtG7/4xS+44447uPHGG2lpaSEcDvOHP/yBoUOH8sILLwCc9rV8veWrgM9MTWFoXroWHRNJVF30tBtjuFzwlClTOHjwIPv376e6upr8/HyGDBnC17/+dZYuXUogEGDfvn0cOHCAwYMHd/t9ly1bxu233w7ABRdcwIgRI9i2bRszZ87ke9/7HpWVlVx77bWMGTOGCRMmcOedd3L33Xdz9dVXM2vWrPPSNl+NwYO3NvwOjcGLSA984hOf4KmnnmLRokUsWLCAxx9/nOrqalatWsXatWspLi6mqalny6B0tbb8DTfcwLPPPktGRgbz58/nlVdeYezYsaxatYoJEyZw77338u1vn58vv/NhwHtTJbv64YqInGrBggUsXLiQp556ik984hMcPXqUoqIiQqEQixcvZvfu3T1+z9mzZ/P4448DsG3bNvbs2cO4cePYsWMH5eXlfPWrX+Waa65h/fr17N+/n8zMTD796U9z5513nrdVKn01RANQXpBFXXMb1cebKcpNj3c5IpIALr74Yo4fP05JSQlDhgzhxhtv5CMf+QgVFRVMnjyZCy64oMfvedttt/GlL32JCRMmkJKSwsMPP0xaWhqLFi3iscceIxQKMXjwYP7pn/6JFStWcNdddxEIBAiFQvz85z8/L+3yX8BHv77vnep6BbyIdNuGDe/N3ikoKGD58uWd7ndi7fjOlJWVtX8Jd3p6Og8//PBp+9x7773ce++9J22bP38+8+fP70XVZ+bLIRrQomMiIr7rwQ/NyyA9pG93EpHY2bBhAzfddNNJ29LS0njjjTfiVFHnfBfwgYBRNihLUyVFEohzrkdzzONtwoQJrF27tk/P2ZuJI4k/RBNug83PkX18e/umUZoqKZIw0tPTOXTokGa+nYFzjkOHDpGe3rPrionfgzeD393KkILLgS8A3jj8HzdW0dwWJi0lGN/6ROSMSktLqayspLq6ust9mpqaehxuftCx3enp6ZSWlvbo+MQP+EAQSqaQW72tfVN5YRYRB3sONTCmODaffhOR8yMUCjFy5Mgz7rNkyRKmTJnSRxX1H+fa7sQfogEoqSCrfhe0NgIwsuC9qZIiIsnKHwFfOo2AC0PVOkBTJUVEwDcBX+HdV64EIDc9REF2mqZKikhS80fAZxfRlFYE+1a2b/LWpFEPXkSSlz8CHjiWOwYqV7U/H1WYpamSIpLUfBTw4+DoHjh+APC+n7W2oZXD9S1xrkxEJD58FPBjvQfRYZr2C60aphGRJOWbgK/LLodASvuF1hOrSupCq4gkK98EfCSYBsXj23vww/IzCAWNdzRVUkSSlG8CHvCmS+5bA5EwKcEAwwdmqgcvIknLZwE/DVqOQ/VWAC4emseaPbVaxEhEklLMA97Mgma2xsyej/W5KIl+4Ck6THPZqEHU1DXzji60ikgS6ose/B3A5j44DwwaBekD2i+0XjaqAIDX3jnUJ6cXEelPYhrwZlYKfBj4VSzP0+GEUDIV9nkfeBo2MIOSARm8tl0BLyLJx2I5Pm1mTwHfB3KAO51zV3eyzy3ALQDFxcVTFy5c2Ktz1dXVkZ2dTdnOJxix+79ZdvkThFMy+PWGZlYfbOOnV2QSSKBvjOmuE+1ONmp3clG7uzZv3rxVzrmKzl6L2XrwZnY1cNA5t8rM5na1n3PuQeBBgIqKCjd3bpe7ntGSJUuYO3culLTC7kXMGpUNI2dxJK+SVxeto2jsJYwvyevVe/dn7e1OMmp3clG7eyeWQzTvA64xs13AQuAKM3sshufzlEz17qMXWmeWe+PwyzUOLyJJJmYB75y71zlX6pwrAxYArzjnPh2r87XLHAgDy9svtA7OS6e8MIvX3qmJ+alFRPoTf82DP6Gkov1CK3jTJd/ceZjWcCSORYmI9K0+CXjn3JLOLrDGTOk0OF4FR/cB3nTJ+pYw6yuP9lkJIiLx5s8efGl0HL5yBQAzygcBsFzDNCKSRPwZ8MUTIJjWfqF1YFYqFw7J1QeeRCSp+DPgU1JhyMSTvuFpZvkgVu4+QlNrOI6FiYj0HX8GPHgXWvevgXAb4F1obWmLsGZPbXzrEhHpI/4N+NIKaGuEg5sAmF4+kIBpHF5Ekoe/Ax7a58PnpoeYUDpA4/AikjT8G/ADRkBmwWnz4dfuraW+uS2OhYmI9A3/BrwZjJgJ21+GiHdh9bJRg2iLOFbsOhzn4kREYs+/AQ8w/uNQ9y7sXApAxYiBhIKmdWlEJCn4O+DHXgVpubDhvwHISA0yZXi+xuFFJCn4O+BDGXDhNfDWs9DaCHjDNBv3H+VoQ2ucixMRiS1/BzzAxE96X8S99Y+Aty6Nc/D6TvXiRcTf/B/wZbMgZ0j7MM3kYQNIDwU0Di8ivuf/gA8EvYutb78EDYdJTQkwrWwg/7tdH3gSEX/zf8ADTLwOIq2w6XeAt7rk2wfrNA4vIr6WHAE/eCIUjDtpmAZgbWVt/GoSEYmx5Ah4M68Xv2c51O5hQmkeZrBub228KxMRiZnkCHiACZ/07jf8N7npIUYVZrNWAS8iPpY8AZ8/AobNgPVPgnNMHjaAtXtrcc7FuzIRkZhInoAHb0589RZ4dwOThw3gcH0LlUca412ViEhMJFfAX3wtBFJgw5PtF1rXaJhGRHwquQI+cyCMfj9seJpxRZmkpQRYq294EhGfSq6AB2+Y5vh+QntfY0JJHmv3Hol3RSIiMZF8AT/2g5Ca0z5Ms3H/MVrDkXhXJSJy3iVfwKdmwoUfgbeeY0ppNi1tEbZUHY93VSIi513yBTzAmCuh+SgVqXsBNEwjIr6UnAFfNguAosMrKMhO1UwaEfGl5Az47CIoGIftepXJwwZoyQIR8aXkDHiAssthz+tcUpLNO9X1HG3UypIi4i/JHfAtdVyWVQnAeq0sKSI+k9wBD4xrWg9oZUkR8Z/kDfjsIii8gIx9rzGqMEsrS4qI7yRvwIPXi9+9nEtKc7SypIj4jgK+tZ4rcvdRU6eVJUXEX5I74Ed44/BTIhsBWKcLrSLiI8kd8NmFUHghRYdXamVJEfGd5A54gLLLCex5nUlDdaFVRPwlZgFvZulm9qaZrTOzTWb2z7E61zmJjsNflV/Fhn1HtbKkiPjGWQPezAJmdlkv3rsZuMI5NwmYDFxlZjN68T6xFZ0PPyO4mea2CFvf1cqSIuIPZw1451wE+GFP39h56qJPQ9Fb/5uHmFUARRcxsm41gIZpRMQ3rDtzv6PDK+uBZ1wPJoubWRBYBYwGHnDO3d3JPrcAtwAUFxdPXbhwYXff/iR1dXVkZ2f36tjRbz/IkKr/R0XbL7m4MJ0vTEjr1fvEw7m0O5Gp3clF7e7avHnzVjnnKjp90Tl31htwHIgArcCx6PNj3Tk2evwAYDEw/kz7TZ061fXW4sWLe32s2/Q/zn0r13335w+7K3+4pPfvEwfn1O4EpnYnF7W7a8BK10Wmdusiq3MuxzkXcM6FnHO50ee53foV5B1fCywBruruMX1qxPsAmJe+le3Vdew93BDngkREzl23Z9GY2TVm9u/R29Xd2L/QzAZEH2cAVwJbel1pLEXH4Se2rSc1GODKH/2FH/55K/XNbfGuTESk17oV8Gb2A+AO4K3o7Y7otjMZAiw2s/XACuAl59zz51JsTJXNIvvAKl7+2kzmXzyYn76ynbn/voQnV+wlHOl/14ZFRM6muz34DwHvd8495Jx7CG+o5UNnOsA5t945N8U5N9E5N9459+1zLTamyi6H1gZKG7byk+un8MxtlzEsP4O/e3o9H/npMl7bXqPFyEQkoaT0YN8BwOHo47zzX0qcRcfh2fUqDL+US4bn8/Stl/H8+ip+8Mct3PCrNyjKSWPSsAFMjt4mluaRkx6Kb90iIl3obsD/C7DGzBYDBswG7o1ZVfGQNQiKLoZdy2D2nQCYGR+ZNJT3X1TMM6v3sXLXYdbureWltw5EX4fRhdnMHlvIRycPZUJJHmYWz1aIiLQ7a8CbWQBviuQMYBpewN/tnHs3xrX1vZGzYNUjcGATFF4AgSAA6aEgN1w6nBsuHQ5AbUML6yuPsnZvLav3HOE3y3fz62U7GVmQxTWThnLN5KGMKky+Obsi0r+cNeCdcxEz+4pz7kng2T6oKX5Gvx/e+AX8/DIIZcHQyTB0CpRMhZJLYMAIMGNAZiqzxxYye2whAEcbW/nTxnf5/bp9/OSVt/mPl99mfEkuX5oziqsnDo1vm0QkaXV3iOYlM7sTWATUn9jonDvc9SEJaMyV8JVVsG8l7FsF+1bDm7+E8M+817OLYdh0GHYpDJsBQyZCShp5GSGumzaM66YN48CxJp5fX8WTK/Zyx8K1DMlLZ+qIgfFtl4gkpe4G/Oei91/usM0B5ee3nH6gYLR3m7TAe97WAgc3eYG/903Y+wZsfs57LZjm9exn3AoXfRSA4tx0Pn/5SK6rKOXDP1nGV3+7lj98dRZ5mboYKyJ9q1urSQL3OOdGnnLzX7h3JiXVG6aZ9gW49kG4Yx18Yytc9yhM/yI0HIYnPwOv/hA6TKPMSQ/xk+uncOBYE/c8s15TLEWkz3V3Nckvn22/pJIz2Ouxz/8efOlVmPBJePnb8NxXIdzavtvkYQO4a/44/rjxXZ54c08cCxaRZNTdDzq9ZGZ3mtkwMxt44hbTyhJFShpc+0uYfResfhSeuA6ajrW//MVZ5cweW8i3n3tLa82LSJ/qbsB/Dq8XvxRv+d9VwMpYFZVwzOCKf4RrfgY7l8JDV8HRSgACAeOHn5xETnqI23+7msaWcJyLFZFk0d3VJE8df0+eMfieuOQmuPEpOLoXfvlXULUOgMKcNH503SS2HajjOy+8FeciRSRZnDHgzezvOjz+5Cmv/Uusikpoo+bB5/4EgRR4/Dpo9oZlZo8t5G/nlPPEG3v444aqOBcpIsngbD34BR0en7o0Qf9c270/KL4IrnsE6t71ZtdEfeP945hUmsc9z2ygTksRi0iMnS3grYvHnT2XjkorYNL1sPwBOPQOAKkpAb51zcUcbWzluXX741ygiPjd2QLedfG4s+dyqivvg2Aq/Pkf2zdNGTaACwbn8FtNmxSRGDtbwE8ys2NmdhyYGH184vmEPqgvseUMhlnfgK1/gO0vA94KlddPH876yqNs3Hc0zgWKiJ+dMeCdc8EO38GaEn184rk+e98dM78M+SPhxXvbPwT111NKSEsJqBcvIjHV7e9klV5KSYP5/wI1W2HFrwDIywhx9cSh/H7tfn3vq4jEjAK+L4z7IIy6AhZ/H+prALjh0mHUNbfx/HpdbBWR2FDA9wUzuOoH0FoPr3wHgEuG5zO2OJsn3twb5+JExK8U8H2lcBxMv8X7xqiq9e0XW9ftrWXTfl1sFZHzTwHfl+bcDZkD4cV7wDk+Fr3YulC9eBGJAQV8X8oYAJf/H9j9v3BkJwMyU/nwhCH8z5p9NLToYquInF8K+L42dr53v+MvAFx/6XCON7fx/HqtTyMi55cCvq8NGg05Q2CnF/AVI/IZXZStOfEict4p4PuaGYyc460bH4m0X2xds6eWzVXHzn68iEg3KeDjoXwONByCg97a8NdOKSE1JcBC9eJF5DxSwMfDyNnefXSYJj8rlQ+NH8wza/bpG59E5LxRwMdDXikMHNV+oRXgumnDON7UxuKtB+NYmIj4iQI+XsrneNMlowuQTS8bSE56CksU8CJynijg42XkHGipg32rAUgJBpg9tpDFW6uJRLTUvoicOwV8vLSPwy9t3zRvXBHVx5t5S7NpROQ8UMDHS+ZAGDyh/UIrwJyxhQAs3qJhGhE5dwr4eBo5B/a+AS0NABTmpDGpNE8XWkXkvFDAx1P5XAi3wN7X2zfNHVfEmr21HK5viV9dIuILCvh4Gj4TAiknj8NfUIRz8Orb1XEsTET8IGYBb2bDzGyxmW02s01mdkeszpWw0rKhpOKk+fATS/IYlJXKKxqHF5FzFMsefBvwDefchcAM4MtmdlEMz5eYyudA1VporAUgEDDmjC3kL9uqCWu6pIicg5gFvHOuyjm3Ovr4OLAZKInV+RLWyDngIrBrWfumeRcUUdvQytq9tfGrS0QSnjkX+16imZUBS4Hxzrljp7x2C3ALQHFx8dSFCxf26hx1dXVkZ2efY6V9zyKtXL7sBqqGvJ/tY24BoL7V8ZWXG7h6VIiPj0k94/GJ2u5zpXYnF7W7a/PmzVvlnKvo9EXnXExvQDawCrj2bPtOnTrV9dbixYt7fWzcPfrXzv1s+kmbPvHz/3Uf/snSsx6a0O0+B2p3clG7uwasdF1kakxn0ZhZCHgaeNw590wsz5XQRs6B6i1w/N32TXPHFbFx3zEOHmuKY2EikshiOYvGgF8Dm51zP4rVeXyhfI53f8qyBQBLtmq6pIj0Tix78O8DbgKuMLO10duHYni+xDV4IqQPOGm65IVDchicm65PtYpIr6XE6o2dc8sAi9X7+0ogCCNneevSOAdmmBnzLijkuXVVtIYjhIL6TJqI9IxSo78YOQeO7oUjO9s3zR1XRF1zGyt3HYljYSKSqBTw/UXZLO9+92vtm943uoBQ0PQlICLSKwr4/qJgLGTkw57l7Zuy01K4dOQgLVsgIr2igO8vAgEYNgP2vH7S5rnjCnn7YB17DzfEqTARSVQK+P5k+Aw4tB3qa9o3zbvAmy756ts1XR0lItIpBXx/Mnymd9+hF19ekEVaSoCdNXVxKkpEEpUCvj8ZOhmCaSeNw5sZpfkZVB5pjF9dIpKQFPD9SUoalEw9bRy+ND9TAS8iPaaA72+GX+qtD9/y3kVVrwevi6wi0jMK+P5m+EyItMG+Ve2bSvMzOdLQSl1zWxwLE5FEo4Dvb4ZN9+47DNOU5mcAsE/DNCLSAwr4/iYjH4ouOulC64mA1zCNiPSEAr4/Gj4D9r4JkTDgDdEAutAqIj2igO+Phs+EluNwYBMABdmppKUE1IMXkR5RwPdHw2d499FxeM2FF5HeUMD3R3nDILfklHF4zYUXkZ5RwPdHZl4vfs9y7wtA0Fx4Eek5BXx/NXwmHK+C2j2A5sKLSM8p4PurU8bhNRdeRHpKAd9fFV0Eabmw9+SA1zCNiHSXAr6/CgShdFqHHrzmwotIzyjg+7PhM+HgW9B4RHPhRaTHFPD92Ylx+L1vai68iPSYAr4/K5kKgZT2+fCaCy8iPaGA789SM2HI5JNm0miIRkS6SwHf3w2f4a0N39qkufAi0iMK+P5u+EwIt0DVWs2FF5EeUcD3d+0feFquufAi0iMK+P4uqwAGlkPlSs2FF5EeUcAngtJpULmCgqyQ5sKLSLcp4BNB6TSoO4Ad26e58CLSbQr4RFBa4d1XrtBceBHpNgV8IigeDynp0XF4zYUXke5RwCeCYAiGTmnvwWsuvIh0hwI+UZRWQNU6hucGAc2FF5GzU8AnitJpEG5mtNsJaC68iJxdzALezB4ys4NmtjFW50gqJd6F1pK6TYDmwovI2cWyB/8wcFUM3z+55JVAzlCyqtdoLryIdEvMAt45txQ4HKv3T0qlFVjlCs2FF5Fu0Rh8IimdBrW7uSi3WQEvImeVEu8CzOwW4BaA4uJilixZ0qv3qaur6/WxiSKvNoUpwOjjK1l8ZDJLlixJinZ3Ru1OLmp378Q94J1zDwIPAlRUVLi5c+f26n2WLFlCb49NGC3TYf03mTWgmh8fhIqZl7Ny+TL/t7sTSfHn3Qm1O7mca7s1RJNIUjOheDzDG94CNBdeRM4sltMkfwssB8aZWaWZfT5W50oqpdPIr91AgIhm0ojIGcVyFs31zrkhzrmQc67UOffrWJ0rqZROI9jWwFir1IVWETkjDdEkmujKktNStqsHLyJnpIBPNAPLIWMgl6XtVA9eRM5IAZ9ozKB0GhNte5cBv2TrQR57fXcfFyYi/U3cp0lKL5ROo+TtP1F7uBrIP+mlP26o4iu/XUM44kgJGAumD49PjSISd+rBJ6LoOPyI5q00trn2zX/e9C63/3YNk0rzmDWmgG/+fiMrd2m1CJFkpYBPRCWX4DCm2NscavQC/uXNB/jyE6sZX5LHI5+bzs+uv4SSARl86bFV7K/VWL1IMlLAJ6L0PJoGjGFKYDs1jREWbz3IrY+t5sIhuTzyuenkpIfIywzxq5sraGqNcMtvVtLYEo531SLSxxTwiap0GlMC21lW2crf/mYVY4qz+c3nLiUvI9S+y+iiHP5jwWQ27T/G3U+vxzl3hjdMDDuq6/jO82/x8MZmXtlygOY2/eIS6Yousiao9JGXkrHxcWqq9zFq8Dge+/yl5GWGTtvvry4s5s4PjOP+P23loqG5fGnOqNPfrK0FandDXimEMvqg+p6JRBx/2VbNw6/t4i/bqgkFjRRzLHl4JdlpKcwdV8j8iwcz74IistP0V1rOk3AbNB+DtiYIZUJqNgS9v1+t4QjNbRHSUgKEgv23n6x/DQnKSqcB8FcZ7/DlL3yG/KzU91480VM3A+C2uaPYXHWMf31xCyPz0xhlldTtWEGgag0DajcypOkdQrQRJkBVaBjVWeOoy78IN3giacMmQyBEW8MR2uqPEG6oJdJYizXVAgYZAyBjAMHMfFKy8glmDSQ1LQPnwOGFc8SBwxEOR2hsbKCpoY7m+mO0NNfT0liHa2kkNTWNrOwccrKzycnJIS8nl+zsbJat38rrK1eSenwPc9MO8ffD6igP1tBy9CAuNYujzRFqtzkatwR4y4JkpKYSMIeZYbjozcDaf3Lej+jEjwoDLPrcnfTjaz+iw7HGmZ041Jyjs/9fsvdK6Dbr8E6DWlvZ8vrpv8h7w3VRSNC1keqaCUWaSHPNpLpm0iJNBIjQYqk0WxotlkaLpdMSSKOVVJx5P8f2mju+tXvvp92Z06qw0+sqaG1l6+u9j6vO2mqn1BN0rWSG68iI1JPh6kl3zacd00SIBpdOvUunnnTCBIgQgEAQZ0HMvMdYwPubFf2PYZ01q11rKJeJ33iu1+3rigI+URWOw6Vmc0/kUUL/+SyEm72eeLgZ2prx/jEZBIJYIIWfWpAfpEPo6RbSrBWAYy6DbcHRrM+5lsa8UWTWV1JYt5URtSsprv0z7MRbTaiH2lyg039QASIErWfDRAuiN0LgXBBrGwY5ZRwJZ1A0KJ/sSJih4VaONTRypK6RxqZmnDOcgwh4j3HRn4Z37hOVec87buv8X6Dr8MjRVUydFG9d7hM5e5Np/7M7aYv3PBxx0MmwlNfK7v/m6LpCRwsp1Fo+LcH3QrzF0nAWJBRpjoZ+kxf8rpmQa+74GxM40U6vHXai/k5+u7kOx3T9k/XaHWnr+NM7+Rf1mdpnp2w/9ed0Ys82S+dAYBCNKVk0BrNoCmTTFMwiHEgjO9BKtjWRZU1k0UQGjaRHGnGRNlwkjIuEiYTD7Y/BRX+vOVzE+5vjXNd/Ri20dtn2c6GAT1SBIHblfRxe+XuKhw6HYCqkpEXv071eRCQMkTZwYSwSJtDcwtZDzYSLJpAzajql5RdRkdp5b7Cp9l1q31lFU+U673SZ+aRkDSAlM5+0nIGkZ+fjnKP5+CFa6g7TVn+EtoYjRBqOQEtDe2/Fov+uzQyzAMG0LFLTs0jNzCY1I4dQehakpBNpa6WhoY76uuM0NNTT1FhHS2MDg4qGUFp+IeSXYbml7f+L/NaSJRRFl1E1IC968zstmys9oYBPZNO/yOaGMRR38y9+JjCxm2+dPmAwg6d+GKZ++Mz7De7mG55FAMiO3kTk/Oi/VwdEROScKOBFRHxKAS8i4lMKeBERn1LAi4j4lAJeRMSnFPAiIj6lgBcR8SnrTysMmlk10NvvmisAas5jOYlC7U4uandy6U67RzjnCjt7oV8F/Lkws5XOuYp419HX1O7konYnl3Ntt4ZoRER8SgEvIuJTfgr4B+NdQJyo3clF7U4u59Ru34zBi4jIyfzUgxcRkQ4U8CIiPpXwAW9mV5nZVjPbbmb3xLueWDKzh8zsoJlt7LBtoJm9ZGZvR+/z41nj+WZmw8xssZltNrNNZnZHdLvf251uZm+a2bpou/85ut3X7T7BzIJmtsbMno8+T5Z27zKzDWa21sxWRrf1uu0JHfBmFgQeAD4IXARcb2YXxbeqmHoYuOqUbfcALzvnxgAvR5/7SRvwDefchcAM4MvRP2O/t7sZuMI5NwmYDFxlZjPwf7tPuAPY3OF5srQbYJ5zbnKH+e+9bntCBzwwHdjunNvhnGsBFgIfjXNNMeOcWwocPmXzR4FHoo8fAf66L2uKNedclXNudfTxcbx/9CX4v93OOVcXfRqK3hw+bzeAmZUCHwZ+1WGz79t9Br1ue6IHfAmwt8Pzyui2ZFLsnKsCLwyBojjXEzNmVgZMAd4gCdodHaZYCxwEXnLOJUW7gf8L/B0Q6bAtGdoN3i/xP5vZKjO7Jbqt121P9C/dtk62ad6nD5lZNvA08DXn3DGzzv7o/cU5FwYmm9kA4HdmNj7OJcWcmV0NHHTOrTKzuXEuJx7e55zbb2ZFwEtmtuVc3izRe/CVwLAOz0uB/XGqJV4OmNkQgOj9wTjXc96ZWQgv3B93zj0T3ez7dp/gnKsFluBdf/F7u98HXGNmu/CGXK8ws8fwf7sBcM7tj94fBH6HNwzd67YnesCvAMaY2UgzSwUWAM/Guaa+9ixwc/TxzcDv41jLeWdeV/3XwGbn3I86vOT3dhdGe+6YWQZwJbAFn7fbOXevc67UOVeG9+/5Fefcp/F5uwHMLMvMck48Bj4AbOQc2p7wn2Q1sw/hjdkFgYecc9+Lb0WxY2a/BebiLSF6APgW8D/Ak8BwYA/wSefcqRdiE5aZXQ68CmzgvTHZv8cbh/dzuyfiXVAL4nXEnnTOfdvMBuHjdncUHaK50zl3dTK028zK8Xrt4A2fP+Gc+965tD3hA15ERDqX6EM0IiLSBQW8iIhPKeBFRHxKAS8i4lMKeBERn1LAS1Ixs3B0pb4Tt/O2aJWZlXVc6VMk3hJ9qQKRnmp0zk2OdxEifUE9eBHa1+H+1+ga7G+a2ejo9hFm9rKZrY/eD49uLzaz30XXa19nZpdF3ypoZr+MruH+5+inUEXiQgEvySbjlCGaT3V47ZhzbjrwM7xPRxN9/KhzbiLwOPCT6PafAH+Jrtd+CbApun0M8IBz7mKgFvh4TFsjcgb6JKskFTOrc85ld7J9F94XbOyILm72rnNukJnVAEOcc63R7VXOuQIzqwZKnXPNHd6jDG9Z3zHR53cDIefcd/ugaSKnUQ9e5D2ui8dd7dOZ5g6Pw+g6l8SRAl7kPZ/qcL88+vg1vFUNAW4ElkUfvwzcCu1fzJHbV0WKdJd6F5JsMqLfknTCi865E1Ml08zsDbyOz/XRbV8FHjKzu4Bq4LPR7XcAD5rZ5/F66rcCVbEuXqQnNAYvQvsYfIVzribetYicLxqiERHxKfXgRUR8Sj14ERGfUsCLiPiUAl5ExKcU8CIiPqWAFxHxqf8PNFIEQMCspQAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the model's training progress using the stats stored in the history object:\n",
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "\n",
    "plot_loss(history)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOM5A9n7QAc5S8QW7qOOowE",
   "collapsed_sections": [],
   "name": "week09.ipynb",
   "provenance": [
    {
     "file_id": "1rbsH-qOENezJeR5XJkpU7uhUaBuwbDM_",
     "timestamp": 1647616242630
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
